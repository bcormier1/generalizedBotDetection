{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/brody/school/38_ve/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import RobertaTokenizer, TFRobertaModel\n",
    "import datasets\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pickle\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset wikitext (/home/brody/.cache/huggingface/datasets/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
      "100%|███████████████████████████████████████████| 3/3 [00:00<00:00, 1036.57it/s]\n"
     ]
    }
   ],
   "source": [
    "wiki = datasets.load_dataset(\"wikitext\",'wikitext-103-v1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LENGTH = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_wiki_set(data_set_type='train',n=10000):\n",
    "    overflow = ''\n",
    "    examples = []\n",
    "    for index,i in tqdm(enumerate(wiki[data_set_type]['text'])):\n",
    "        buffer = overflow + i\n",
    "        if len(buffer) >= MAX_LENGTH:\n",
    "            examples.append(buffer[:MAX_LENGTH])\n",
    "            overflow = ''\n",
    "        else:\n",
    "            overflow += i\n",
    "        if index >= n:\n",
    "            break\n",
    "    return examples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [00:00, 146143.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " = Valkyria Chronicles III = \n",
      " Senjō no Valkyria 3 : <unk> Chronicles ( Japanese : 戦場のヴァルキュリア3 , lit . Valkyria of the Battlefield 3 ) , commonly referred to as Valkyria Chronicles III outside Japan , is a tactical role @-@ playing video game developed by Sega and Media.Vision for the PlayStation Portable . Released in January 2011 in Japan , it is the third game in the Valkyria series . Employing the same fusion of tactical and real @-@ time gameplay as its predecessors , the story runs paralle\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "wiki_examples = create_wiki_set(data_set_type='train',n=10)\n",
    "print(wiki_examples[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TFBaseModelOutputWithPoolingAndCrossAttentions(last_hidden_state=<tf.Tensor: shape=(1, 8, 768), dtype=float32, numpy=\n",
       "array([[[-0.04778079,  0.08856517, -0.00979672, ..., -0.05444449,\n",
       "         -0.06716338, -0.00391623],\n",
       "        [-0.07121383,  0.01499833, -0.1298776 , ...,  0.06383334,\n",
       "          0.02963825, -0.08603133],\n",
       "        [ 0.09055017,  0.14373958,  0.08283181, ...,  0.05086066,\n",
       "         -0.03197741, -0.04901589],\n",
       "        ...,\n",
       "        [ 0.08531624,  0.21548253,  0.08490154, ..., -0.11496733,\n",
       "          0.03299987, -0.07903446],\n",
       "        [ 0.16793376,  0.128793  ,  0.00646019, ...,  0.03671372,\n",
       "         -0.06305141,  0.02762577],\n",
       "        [-0.04356978,  0.08920526, -0.03888651, ..., -0.09573355,\n",
       "         -0.07437792, -0.02838535]]], dtype=float32)>, pooler_output=<tf.Tensor: shape=(1, 768), dtype=float32, numpy=\n",
       "array([[-3.20835412e-03, -2.19398811e-01, -2.10875914e-01,\n",
       "        -7.67211840e-02,  1.20515734e-01,  2.04878107e-01,\n",
       "         2.60702759e-01, -8.43434557e-02, -7.25212172e-02,\n",
       "        -1.70245662e-01,  2.10894465e-01, -2.10080706e-02,\n",
       "        -8.20225626e-02,  1.01770028e-01, -1.44240707e-01,\n",
       "         4.92009878e-01,  2.12017640e-01, -4.57427651e-01,\n",
       "         3.59925367e-02, -1.54097788e-02, -2.72182375e-01,\n",
       "         8.27794075e-02,  4.70065057e-01,  3.35531026e-01,\n",
       "         1.15759946e-01,  6.07131459e-02, -1.33749053e-01,\n",
       "        -1.28289824e-02,  1.83979839e-01,  2.20602602e-01,\n",
       "         2.86060303e-01,  6.49519041e-02,  8.11276287e-02,\n",
       "         2.38027632e-01, -2.40373775e-01,  6.31177351e-02,\n",
       "        -3.10757160e-01,  2.31245067e-02,  2.60800332e-01,\n",
       "        -1.86507851e-01, -7.94521198e-02,  1.64428204e-01,\n",
       "         2.10449129e-01, -1.18400335e-01, -1.12902522e-01,\n",
       "         4.05719608e-01,  2.56426215e-01,  1.24019133e-02,\n",
       "        -1.40121520e-01, -9.03729349e-02, -3.54312032e-01,\n",
       "         3.36890906e-01,  2.84835756e-01,  1.95041850e-01,\n",
       "        -3.88983870e-03,  5.92864379e-02, -1.45375699e-01,\n",
       "         2.51302689e-01, -8.08212087e-02, -9.21375155e-02,\n",
       "        -1.17701449e-01, -2.02876329e-01, -1.32955713e-02,\n",
       "        -5.46009243e-02,  2.95995660e-02, -1.40465602e-01,\n",
       "         9.00239944e-02, -1.46244109e-01, -1.41902789e-01,\n",
       "         5.48128933e-02, -8.58305469e-02,  1.53002515e-01,\n",
       "         1.69136807e-01, -2.95962930e-01, -2.91939050e-01,\n",
       "         4.43661176e-02, -5.87140739e-01, -9.92226452e-02,\n",
       "         2.96371132e-01,  4.26589400e-01, -1.20493628e-01,\n",
       "         1.85383514e-01,  3.91205288e-02,  2.10799828e-01,\n",
       "        -1.10536814e-04, -4.03327532e-02, -3.02921757e-02,\n",
       "        -1.13737464e-01,  1.92575112e-01,  2.70846277e-01,\n",
       "        -1.98716417e-01, -3.77652884e-01,  6.66286573e-02,\n",
       "         1.19770812e-02, -9.29620638e-02,  2.19942592e-02,\n",
       "        -2.38061827e-02, -9.62426737e-02, -1.54129207e-01,\n",
       "        -1.67303458e-01,  5.45956753e-02, -2.69671708e-01,\n",
       "        -1.40773878e-01,  2.65931934e-01, -3.28430608e-02,\n",
       "        -1.97120741e-01, -7.78406672e-03,  3.11605662e-01,\n",
       "         7.45204464e-02, -1.16908878e-01, -1.90019906e-01,\n",
       "         4.27071571e-01,  3.08910906e-01,  1.99038535e-04,\n",
       "         3.09021841e-03,  1.75333872e-01,  1.32558957e-01,\n",
       "        -2.92308658e-01,  4.09372717e-01, -3.13201427e-01,\n",
       "        -1.78365782e-02, -9.42375660e-02,  1.11460842e-01,\n",
       "         1.59942210e-01, -2.21162051e-01,  2.85683036e-01,\n",
       "         1.37039304e-01,  2.68404692e-01,  1.80570111e-01,\n",
       "         1.06966279e-01, -2.95007527e-02,  1.45060733e-01,\n",
       "        -9.14728567e-02,  1.30431533e-01,  2.32660145e-01,\n",
       "         1.15183868e-01, -8.29361286e-03, -3.29770863e-01,\n",
       "        -2.05752045e-01,  2.69434959e-01,  3.41006100e-01,\n",
       "         1.58482626e-01, -5.10633253e-02,  1.89969853e-01,\n",
       "         8.57245475e-02,  2.21281230e-01,  1.43722787e-01,\n",
       "        -4.10222769e-01,  4.19181585e-02,  3.50817084e-01,\n",
       "         9.59414765e-02,  1.56078443e-01, -7.97151998e-02,\n",
       "        -2.80920953e-01, -2.64110923e-01, -8.83056894e-02,\n",
       "         5.00719175e-02, -3.28754365e-01, -1.32081404e-01,\n",
       "         3.65294904e-01,  2.14692689e-02, -9.13008396e-03,\n",
       "        -1.41113535e-01, -2.46367082e-01, -2.38322504e-02,\n",
       "        -1.23165026e-01,  1.06486222e-02,  1.10225715e-01,\n",
       "        -8.72697234e-02, -4.04573619e-01, -8.67537335e-02,\n",
       "        -5.57479680e-01, -1.05601937e-01,  1.71130121e-01,\n",
       "        -3.24255645e-01,  2.53680497e-01, -2.76805073e-01,\n",
       "         1.02617063e-01,  4.02728915e-01,  4.10414785e-02,\n",
       "        -6.04181597e-03, -1.88274935e-01, -1.89641565e-02,\n",
       "         9.24247950e-02,  3.31841797e-01,  2.45441973e-01,\n",
       "        -4.00647253e-01,  1.12104788e-01,  1.43804550e-01,\n",
       "         2.54461855e-01,  1.42715216e-01, -5.58097996e-02,\n",
       "        -1.28639355e-01,  1.56570539e-01, -2.00989634e-01,\n",
       "         1.79555342e-01, -2.21088782e-01,  1.80278227e-01,\n",
       "        -2.55239904e-01, -2.14609280e-01,  2.89018661e-01,\n",
       "        -3.99546087e-01, -2.03513447e-02,  8.74466076e-02,\n",
       "         2.68948913e-01,  1.29506178e-02, -3.03633306e-02,\n",
       "        -7.79506266e-02,  1.22122176e-01,  1.90515310e-01,\n",
       "         1.34314030e-01, -3.86831135e-01,  2.65822083e-01,\n",
       "        -2.70696189e-02, -2.07917485e-02, -2.93000471e-02,\n",
       "         1.62729949e-01,  2.45736971e-01,  9.68206972e-02,\n",
       "        -3.85696143e-01, -1.40931979e-01,  1.15571566e-01,\n",
       "         2.88035363e-01, -2.23671019e-01,  1.64160088e-01,\n",
       "        -2.81541824e-01, -3.90870959e-01, -1.50209859e-01,\n",
       "         2.10859701e-01,  2.31049985e-01,  1.68566480e-01,\n",
       "        -2.72874892e-01,  1.63064003e-01, -9.61965024e-02,\n",
       "        -4.29663271e-01, -3.66993457e-01, -1.07383884e-01,\n",
       "         2.50065655e-01,  1.72849178e-01,  1.88412786e-01,\n",
       "         2.37282708e-01,  3.97718400e-02,  1.20347865e-01,\n",
       "         1.44975558e-01,  1.55796409e-01, -1.50204033e-01,\n",
       "         1.90349638e-01, -3.56269479e-01, -5.85167445e-02,\n",
       "        -2.66237974e-01, -1.92025706e-01, -1.94656208e-01,\n",
       "         3.98378432e-01, -2.30641395e-01,  2.33293861e-01,\n",
       "         3.87280822e-01, -3.04069966e-01, -1.15069799e-01,\n",
       "         1.48588642e-01,  9.19808820e-02,  9.46981534e-02,\n",
       "        -1.17586061e-01,  1.95303455e-01,  1.48202315e-01,\n",
       "        -1.09415665e-01,  2.52500534e-01,  2.31210818e-03,\n",
       "         2.53496110e-01,  1.68595076e-01,  8.71359408e-02,\n",
       "         1.35134220e-01,  1.27087444e-01, -1.48624793e-01,\n",
       "         6.07507266e-02,  9.33445431e-03, -1.52348960e-02,\n",
       "        -2.31772855e-01, -1.58350185e-01,  2.31593430e-01,\n",
       "        -5.20966612e-02,  2.36924198e-02, -1.70812771e-01,\n",
       "        -1.12163700e-01,  2.90004518e-02,  4.03673619e-01,\n",
       "        -3.58097434e-01,  2.51180977e-01,  7.63967037e-02,\n",
       "         1.57716975e-01, -2.49080643e-01, -2.25926474e-01,\n",
       "         8.81317630e-02,  1.78568467e-01, -4.11153138e-01,\n",
       "         1.01238852e-02,  1.70343921e-01,  9.30642262e-02,\n",
       "         2.06053570e-01,  2.60113955e-01,  8.85624066e-03,\n",
       "        -1.15994424e-01,  4.90979046e-01, -1.61067083e-01,\n",
       "        -1.08544350e-01,  2.57025033e-01, -2.70816386e-01,\n",
       "        -2.79375583e-01,  2.48958617e-01, -2.87712514e-02,\n",
       "         2.99324363e-01,  1.26215771e-01,  5.40378913e-02,\n",
       "         7.49165565e-02, -6.00177467e-01,  6.10343181e-02,\n",
       "        -4.53015894e-01,  9.61085130e-03,  2.22184360e-02,\n",
       "        -8.25161338e-02, -1.98490947e-01,  1.48977339e-01,\n",
       "         2.96525747e-01, -2.56673664e-01, -2.87930351e-02,\n",
       "         1.88628480e-01,  6.92571178e-02, -1.23533025e-01,\n",
       "         4.75476474e-01, -1.03991870e-02,  2.11918890e-01,\n",
       "        -5.57040274e-02,  2.72053331e-01, -2.14468285e-01,\n",
       "         2.68447578e-01, -2.73713499e-01, -7.97929689e-02,\n",
       "         1.96780413e-02,  7.93839917e-02,  6.90158308e-02,\n",
       "        -6.24677986e-02, -3.39709640e-01,  2.35161781e-01,\n",
       "        -7.93724880e-03, -5.41508980e-02, -3.69961224e-02,\n",
       "         1.02098070e-01,  8.38435953e-04,  4.83319610e-02,\n",
       "         5.84419630e-02,  3.12681675e-01,  2.29631141e-01,\n",
       "        -1.59875192e-02, -3.71129543e-01, -2.71662269e-02,\n",
       "        -8.35823417e-02,  3.86972688e-02,  4.89381179e-02,\n",
       "        -1.57828685e-02,  4.39692676e-01, -8.11677799e-02,\n",
       "         3.53093352e-03, -1.42843679e-01,  2.61004537e-01,\n",
       "         2.11246416e-01,  1.26272008e-01,  1.21504202e-01,\n",
       "         5.61257116e-02,  1.27897829e-01, -5.34672067e-02,\n",
       "        -7.77304498e-03, -1.56708181e-01, -2.33479589e-01,\n",
       "        -2.75325239e-01,  2.08815768e-01, -2.39050195e-01,\n",
       "        -1.64440319e-01,  1.60898685e-01,  2.13066816e-01,\n",
       "        -1.54470757e-01,  1.44508615e-01,  3.04993361e-01,\n",
       "         1.03659652e-01, -1.48999706e-01,  2.66285807e-01,\n",
       "        -1.08612746e-01,  9.78242457e-02,  3.17536443e-01,\n",
       "        -1.55099155e-02,  1.78095445e-01,  4.90861505e-01,\n",
       "         2.11000264e-01, -3.69210333e-01, -3.94604206e-02,\n",
       "        -2.12497726e-01, -2.95321876e-03,  2.37470895e-01,\n",
       "        -1.47297293e-01,  2.02547729e-01,  3.85129422e-01,\n",
       "         3.06374103e-01,  4.56059247e-01,  8.66976660e-03,\n",
       "        -1.33133337e-01,  8.31007659e-02,  2.19721362e-01,\n",
       "         3.52087133e-02, -1.52064025e-01, -1.82708472e-01,\n",
       "         2.53969640e-01,  5.98566644e-02, -1.41932696e-01,\n",
       "        -3.83067653e-02, -1.45527452e-01,  4.71653305e-02,\n",
       "        -1.33252501e-01, -3.94326091e-01,  4.24360037e-02,\n",
       "         1.94291025e-01, -4.80013311e-01,  8.42619762e-02,\n",
       "        -2.76828051e-01,  3.64395678e-02, -2.34952360e-01,\n",
       "         2.10428059e-01, -2.14833766e-01, -1.16945967e-01,\n",
       "         3.99198383e-01, -8.22381377e-02,  5.33655770e-02,\n",
       "        -1.81993872e-01, -1.42749161e-01,  2.00184714e-02,\n",
       "         1.15067950e-02, -3.60208303e-02, -2.61897221e-02,\n",
       "         3.34181428e-01, -1.30556464e-01,  3.29882130e-02,\n",
       "         2.24990733e-02,  2.07253948e-01, -3.88171002e-02,\n",
       "         1.98677108e-01,  2.05992144e-02, -1.32148027e-01,\n",
       "        -3.74775290e-01,  1.37686551e-01, -1.99719638e-01,\n",
       "        -4.21547860e-01, -3.75748485e-01,  3.54461610e-01,\n",
       "        -1.21602431e-01, -2.48048946e-01, -2.11665630e-01,\n",
       "        -2.57440507e-01,  7.95759931e-02,  1.77274376e-01,\n",
       "         4.61063057e-01, -3.83631557e-01, -8.99177715e-02,\n",
       "         4.67975348e-01, -6.33113384e-02, -1.83109462e-01,\n",
       "         2.96509862e-01,  1.80378720e-01, -3.35837752e-01,\n",
       "         3.33576500e-01,  2.59956956e-01, -4.43896949e-02,\n",
       "         2.14323141e-02,  5.14500678e-01,  1.27648681e-01,\n",
       "         2.09132195e-01, -2.31019288e-01,  4.49822962e-01,\n",
       "        -2.21964628e-01,  3.20710182e-01, -1.43692017e-01,\n",
       "        -2.13017955e-01, -2.24353179e-01, -5.35157137e-03,\n",
       "         3.32329512e-01,  1.80818453e-01, -4.20105398e-01,\n",
       "        -1.12855799e-01,  4.20588441e-02,  3.38003486e-01,\n",
       "        -3.84709299e-01, -9.51941609e-02,  1.41457664e-02,\n",
       "        -3.56040627e-01,  1.03133976e-01,  9.50982496e-02,\n",
       "         2.25736484e-01, -3.78652871e-01,  3.62465973e-03,\n",
       "         4.05021966e-01, -3.09433401e-01,  1.25502035e-01,\n",
       "         3.03708702e-01,  8.10050368e-02,  3.37606847e-01,\n",
       "        -4.38283682e-02, -3.55926086e-03,  4.55769785e-02,\n",
       "        -2.23708481e-01, -3.73146273e-02,  1.38598427e-01,\n",
       "         5.53459108e-01,  1.48177356e-01, -3.81702840e-01,\n",
       "         8.53189453e-02,  2.43814170e-01, -1.77003711e-01,\n",
       "         3.03410470e-01, -8.32461640e-02, -5.37493490e-02,\n",
       "         2.68746108e-01, -4.74042930e-02,  1.45662785e-01,\n",
       "        -8.51082280e-02, -2.34766662e-01, -3.02374333e-01,\n",
       "         3.72062206e-01, -2.14252189e-01, -1.13997847e-01,\n",
       "        -1.58389300e-01, -1.17158659e-01, -1.41414911e-01,\n",
       "         3.60584110e-02, -3.95093739e-01,  3.37784857e-01,\n",
       "         1.23257890e-01, -2.11187914e-01, -9.71143320e-02,\n",
       "        -9.19383392e-02, -1.63676471e-01, -2.25340128e-01,\n",
       "        -2.61481255e-01,  4.41721827e-01, -1.58480570e-01,\n",
       "        -4.50320154e-01,  2.57696241e-01,  2.48039942e-02,\n",
       "         3.40881974e-01,  3.57584357e-02,  1.01790577e-01,\n",
       "        -4.35351878e-02,  1.30057111e-01,  1.02018915e-01,\n",
       "        -1.23192519e-01,  2.68384248e-01,  5.63500710e-02,\n",
       "        -5.59554696e-01, -1.21658668e-01, -2.08712190e-01,\n",
       "         7.01977313e-02,  1.92833558e-01, -3.40267181e-01,\n",
       "         1.83589533e-02,  3.04272007e-02,  1.41745582e-01,\n",
       "         2.05197092e-02, -1.10924438e-01, -7.23680779e-02,\n",
       "         4.05556351e-01,  2.38585278e-01,  2.84832627e-01,\n",
       "         9.04108435e-02,  2.41680309e-01, -1.55831929e-02,\n",
       "        -3.35555732e-01,  3.57194915e-02,  8.47159475e-02,\n",
       "        -1.99511960e-01,  4.24500048e-01, -1.03254683e-01,\n",
       "        -3.91195238e-01, -6.81239143e-02,  3.96967381e-01,\n",
       "         1.10351965e-01, -2.60562487e-02, -4.74279560e-02,\n",
       "         2.01513410e-01,  1.60932779e-01, -1.37656942e-01,\n",
       "         1.90950975e-01, -4.21219207e-02, -1.41722724e-01,\n",
       "        -1.16266742e-01,  8.01678747e-02, -2.17977569e-01,\n",
       "         4.42189425e-02, -1.44717634e-01, -9.56381392e-03,\n",
       "        -2.00814664e-01,  7.95970019e-03, -1.90851524e-01,\n",
       "         2.55983353e-01, -3.37126285e-01,  1.14069864e-01,\n",
       "         7.07078576e-02,  2.94569165e-01, -3.43978435e-01,\n",
       "        -1.65677950e-01, -6.88137636e-02,  1.56920895e-01,\n",
       "         2.68606544e-01,  3.48458529e-01,  2.13631205e-02,\n",
       "         1.21829538e-02, -1.54401094e-01, -2.58027613e-01,\n",
       "         7.18437880e-02, -1.93896934e-01,  1.39839128e-01,\n",
       "         7.08630383e-02,  2.62113750e-01, -3.03361446e-01,\n",
       "        -1.88471347e-01,  2.22629875e-01, -1.07453465e-01,\n",
       "        -1.54276013e-01,  4.08734679e-01,  2.41009220e-01,\n",
       "         2.14567006e-01,  2.52576545e-02,  2.47452497e-01,\n",
       "         3.04050408e-02, -1.74306452e-01, -1.26085475e-01,\n",
       "        -2.50280708e-01,  7.94503540e-02, -7.41636828e-02,\n",
       "        -5.30130267e-02, -6.41489774e-02, -1.04493357e-01,\n",
       "        -2.06506178e-01, -1.66208416e-01,  1.38979912e-01,\n",
       "         1.46125808e-01,  3.67618129e-02, -5.05397208e-02,\n",
       "        -2.27870047e-02, -2.76609540e-01,  2.96194643e-01,\n",
       "         2.02105418e-02,  7.43673816e-02, -6.51659444e-02,\n",
       "         2.90482864e-02, -1.45913571e-01,  2.40871921e-01,\n",
       "         2.10742623e-01,  9.09499675e-02, -1.99213982e-01,\n",
       "        -4.87106591e-02, -2.82545775e-01, -3.61319721e-01,\n",
       "         6.19724058e-02,  1.38653949e-01,  1.05568230e-01,\n",
       "        -6.88275918e-02, -2.82527655e-01, -1.02485577e-02,\n",
       "        -1.45787120e-01,  1.74985990e-01,  1.53910546e-02,\n",
       "        -1.53217718e-01, -8.27573389e-02, -5.33861592e-02,\n",
       "        -5.51173463e-02,  7.97339603e-02, -2.17710793e-01,\n",
       "        -1.88134775e-01, -1.18729241e-01, -6.53318986e-02,\n",
       "        -7.35756531e-02,  3.53047729e-01, -4.66192439e-02,\n",
       "         2.82075197e-01, -1.48586452e-01,  1.07349409e-03,\n",
       "        -1.66373372e-01,  1.13654107e-01, -6.27936423e-02,\n",
       "         6.21112436e-02,  2.78822601e-01, -4.40709680e-01,\n",
       "        -1.60827056e-01, -2.96949618e-03, -2.13256031e-01,\n",
       "        -1.65362239e-01, -6.15230538e-02, -3.72082889e-02,\n",
       "         2.30685785e-01, -3.40577304e-01,  2.32357278e-01,\n",
       "        -1.20225221e-01,  1.92554653e-01, -7.20600486e-02,\n",
       "        -2.55192578e-01, -1.59226045e-01,  1.68811847e-02,\n",
       "         2.47110665e-01, -3.47247034e-01, -2.32618764e-01,\n",
       "        -2.77012408e-01, -1.03173070e-01, -9.32721794e-02,\n",
       "        -2.60390788e-01,  4.25467372e-01, -1.07975043e-01,\n",
       "        -7.44473487e-02,  1.90670807e-02,  4.43330705e-01,\n",
       "         2.06673980e-01,  1.46707669e-01,  2.12718159e-01,\n",
       "        -1.55562721e-02,  2.98302602e-02,  1.13627359e-01,\n",
       "        -4.58241671e-01,  2.29588926e-01, -2.31054947e-01,\n",
       "        -1.19013317e-01, -2.55083456e-03,  8.79378170e-02,\n",
       "        -2.85784509e-02,  1.00002550e-02, -1.33525833e-01,\n",
       "        -1.12019874e-01,  2.16943413e-01, -3.68301898e-01,\n",
       "        -3.18599269e-02,  2.55869031e-01,  1.54189110e-01,\n",
       "        -2.50107050e-01,  4.01220359e-02,  1.13599047e-01,\n",
       "         3.76821220e-01,  1.00478001e-01, -2.25016668e-01,\n",
       "         1.27526373e-01, -3.43337715e-01, -4.19576950e-02,\n",
       "        -1.91375822e-01, -2.92332470e-01,  1.55397221e-01,\n",
       "        -6.11723177e-02,  7.52292797e-02, -8.88148770e-02,\n",
       "        -2.94407517e-01,  2.15898022e-01, -5.99371791e-02,\n",
       "        -7.05182180e-02,  4.17251319e-01,  3.51346359e-02,\n",
       "        -1.30387709e-01,  1.53218076e-01,  6.31484343e-03,\n",
       "         7.28415698e-03, -1.01523824e-01,  2.61933208e-01,\n",
       "         2.16599420e-01, -2.74035037e-01,  1.44592419e-01,\n",
       "        -1.34544015e-01, -3.17012854e-02, -1.12099282e-01]], dtype=float32)>, past_key_values=None, hidden_states=None, attentions=None, cross_attentions=None)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_base_roberta(learning_rate = 0.00001,\n",
    "                      dropout=0.3,\n",
    "                      hidden_size=100):\n",
    "    \n",
    "    model = TFRobertaModel.from_pretrained(\"roberta-base\")\n",
    "    \n",
    "    input_ids = tf.keras.layers.Input(shape=(100,), dtype=tf.int64, name='input_ids_layer')\n",
    "    attention_mask = tf.keras.layers.Input(shape=(100,), dtype=tf.int64, name='attention_mask_layer')\n",
    "    \n",
    "\n",
    "    bert_inputs = {'input_ids': input_ids,\n",
    "                   'attention_mask': attention_mask}         \n",
    "\n",
    "    bert_out = model(bert_inputs)[1]\n",
    "    \n",
    "    hidden = tf.keras.layers.Dense(hidden_size, activation='relu', name='hidden_layer')(bert_out)\n",
    "    dropped = tf.keras.layers.Dropout(dropout)(hidden)  \n",
    "\n",
    "    classification = tf.keras.layers.Dense(1, activation='sigmoid',name='classification_layer')(dropped)\n",
    "\n",
    "    \n",
    "    detection_model = tf.keras.Model(inputs=[input_ids, attention_mask], outputs=[classification])\n",
    "    \n",
    "    detection_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "                            loss='binary_crossentropy', \n",
    "                            metrics=['accuracy',tf.keras.metrics.Precision(),tf.keras.metrics.Recall()]) \n",
    "    return detection_model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/home/brody/school/w266/data/generated_wiki_text_10k.data', 'rb') as f:\n",
    "    generated_texts = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "145"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(generated_texts[0].split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ". At the height of his popularity in 1882 he became one of Europe's leading entertainers. He became one of Europe's most well @-@ known musicians, selling over 10 @,@ 000 @,@ 000 albums as of 2015. He is widely regarded as one of Europe's most successful musicians, receiving accolades such as the Royal Philharmonic Lifetime Achievement Award in 2002. He was inducted into the Grammy Hall of Fame in 1988, and continues to perform at the Academy of Motion Picture Arts and Sciences every year thereafter, and has been featured on Rolling Stone's list of America's 100 Greatest Musicians of All @-@ Decade. \n",
      " = = Early life = = \n",
      " John Lewis Lewis was born on March 3, 1872, the youngest son of James Lewis and Margaret Alice Lewis. He grew up in New Haven, New Haven, Connecticut, where he moved with his mother and elder brother to Providence, Rhode Island when he was four years of age. Shortly thereafter, his parents emigrated to the West Indies, where it was rumoured that the Lewis family was descended from a Native American tribesman, but this never occurred. When Lewis was ten years old, his father\n",
      "------------------------------------------------------------------------\n",
      "------------------------------------------------------------------------\n",
      "'s success in North America. \n",
      " = = Reception = = \n",
      " = = Track listing = = \n",
      " All songs written and co @-@ written by Jon Bon Jovi. \n",
      " = = Charts = = \n",
      " = = Certifications = = \n",
      " = M @-@ 53 ( Michigan highway ) = \n",
      " M @-@ 53 is a state trunkline state trunkline highway in the U.S. state of Michigan that originates just east @-@ southeast of Kalamazoo. It runs 1 1 ⁄ 2 @-@ mile ( 0 @.@ 62 km ) northward from an intersection with I @-@ 495 ( Michigan Avenue ) to I @-@ 695's southern terminus. The western terminus is I @-@ 495, which terminates at M @-@ 53's northern terminus. \n",
      " = = Route description = = \n",
      " M @-@ 53 begins just east @-@ southeast of I @-@ 495's southern terminus at an I @-@ 495 interchange. Northbound M @-@ 53 merges I @-@ 495's western terminus and\n",
      "------------------------------------------------------------------------\n",
      "------------------------------------------------------------------------\n",
      " was released. \n",
      " = = Gameplay = = \n",
      " Grand Theft Auto : San Andreas is a turn @-@ and @-@ a @-@ half @-@ hour shoot'em @-@ up in which the player assumes the role of Samus Aran. Samus acquires power @-@ ups scattered throughout the game's environments in order to progress through the game's campaign. These power @-@ ups vary depending on which power @-@ up Samus wields, and Samus is equipped with special power @-@ ups in addition to standard power @-@ ups. For example, Samus acquires a power @-@ up similar to Gung @-@ Ho's power @-@ @-@ @-@ @-@ @-@ @-@ @-@ @-@ @-@ @-@ @-@ @-@ @-@ @-@ @-@ @-@ @-@ @-@ @-@ @-@ @-@ @-@ @-@ @-@ @-@ @-@ @-@ @-@ @-@ @-@ @-@ @-@ @-\n",
      "------------------------------------------------------------------------\n",
      "------------------------------------------------------------------------\n",
      ", \" and \" The Man With The Golden Claws \". On February 2, 2012, Beyoncé performed \" Don 't Stop Believin'\" on The Ellen DeGeneres Show. \n",
      " = = Formats and track listings = = \n",
      " = = Charts and certifications = = \n",
      " Notes \n",
      " ^ a signifies a co @-@ producer \n",
      " ^ b signifies an additional co @-@ producer \n",
      " ^ c signifies an additional producer \n",
      " ^ d signifies an additional producer \n",
      " ^ e signifies an additional producer \n",
      " ^ f signifies an additional producer \n",
      " ^ g signifies an additional producer \n",
      " ^ h signifies an additional producer \n",
      " ^ i signifies an additional producer \n",
      " ^ j signifies an additional producer \n",
      " ^ k signifies an additional producer \n",
      " ^ l signifies an additional producer \n",
      " ^ m signifies an additional producer \n",
      " ^ o signifies an additional producer \n",
      " ^ p signifies an additional producer \n",
      " ^ q signifies an additional producer \n",
      " ^ r signifies an additional producer \n",
      " ^ s signifies an additional producer \n",
      " ^ t signifies an additional producer \n",
      " ^ u signifies an additional producer \n",
      " ^ v signifies an additional producer \n",
      " ^ w signifies an additional producer \n",
      "------------------------------------------------------------------------\n",
      "------------------------------------------------------------------------\n",
      " that he had been unable to portray onscreen during the filming process, she said it was a \" dream of mine \" to be involved in Disney's live @-@ action live action adventure films. She elaborated : \" I just thought,'It's kind of cool. It's like I'm making a movie out there and I'm happy I made it. I didn ’ t know what I was supposed to do.'I wasn ’ t able to tell them where I was supposed to go with it. So I kind of decided to go home and look at the film as if it couldn ’ t happen. It's great to be able to work with them again because they ’ re kind of my dad ’ s family, so there ’ s going to be a lot of laughter out there. \" \n",
      " = = Reception = = \n",
      " = = = Box @-@ office = = = \n",
      " Toy Story 3 opened its North American debut on November 11, 2006, grossing US $ 29 @.@ 5 million in 3 @,@ 495 theaters in its first @-@ weekend box @-@ office performance. \n",
      " Toy Story 3 was\n",
      "------------------------------------------------------------------------\n",
      "------------------------------------------------------------------------\n",
      ", as well @-@ known examples exist such as those developed for use in nuclear propulsion. \n",
      " = = History = = \n",
      " = = = Early history = = = \n",
      " It is unclear exactly when the development of the nuclear @-@ powered electric locomotives began, or who is known to have been involved in the development and use of them. The first electric locomotives were produced between 1819 and 1824. By the end of World War I, it was apparent that electric locomotives were becoming more widely available, allowing them to be operated more efficiently than coal @-@ fired locomotives such as that of locomotives belonging to different classes. \n",
      " Electric locomotives were introduced into locomotives starting in 1819. It is possible that locomotives were designed and manufactured primarily for use in locomotives designed for use in coal @-@ fired locomotives. \n",
      " = = Development = = \n",
      " = = = Background = = = \n",
      " During the Napoleonic Wars in 1814 – 1815, steam locomotives were used to transport troops as part of France's campaign in the Seven Years'War against the Kingdom of Great Britain. It is\n",
      "------------------------------------------------------------------------\n",
      "------------------------------------------------------------------------\n",
      ". Since then, it has been used as a counter @-@ tool in attacks on military targets, such as air bases, dams, mines and oil facilities. \n",
      " = = Taxonomy = = \n",
      " The generic name Collybia comes from the Greek words phallus ( σοῦφόνος ) meaning \" plough @-@ and @- @-@ thorn @-@ spike @-@ plough \", \" plough @-@ and @-@ twig @-@ tree \" and σουλέούῦνούῦς meaning plough @-@ and @-@ twig @-@ tree. \n",
      " Collybia is most commonly known for its plough @-@ and @-@ twig @-@ tree appearance ; it can also be distinguished microscopically from other Collybia species, such as those found in Europe and Australia, as well as those found in Asia and North America, as illustrated below. \n",
      " = = Distribution and habitat = = \n",
      " Collybia can be found throughout North @-@ East Asia, Central America,\n",
      "------------------------------------------------------------------------\n",
      "------------------------------------------------------------------------\n",
      " = = Background = = \n",
      " In December 2012, the U.S Department of Homeland Security ( Homeland Security Administration ) released a memorandum of understanding ( Memorandum of Understanding ) for the implementation of President Barack Obama ’ s Homeland Security Reinvestment and Reinvestment Program ( H.R. 2782 ), which aims \" to enhance the safety and well @-@ being of U.S. citizens living in low @-@ security areas \", among other initiatives. On June 1, 2013, President @-@ in @-@ Chief John F. Kennedy issued Executive Order 1126, directing Immigration and Naturalization Service ( INS @-@ INS @-@ REV ) to work to enhance Homeland Security Reinvestment Program ( H.R @-@ 2782 ). According to the U.S. Department of Homeland @-@ Insular Affairs, H.R @-@ 2782 was designed to increase security for residents of low @-@ security @-@ designated U.S @-@ flagged countries such as Honduras, El Salvador, Guatemala, El Salvador @-@ Panama, El Salvador @-@ Belize @-@ Guatemala @-@ Nicaragua @-@ Belize @-\n",
      "------------------------------------------------------------------------\n",
      "------------------------------------------------------------------------\n",
      ". This has to do with two factors. First of all, there may not be enough fat soluble lipids in the blood to compensate for weight loss in athletes who have diabetes. Secondly there is not enough fat soluble lipids in the bloodstream to compensate for weight loss in athletes who have diabetes who do not have Type 2 diabetes. As a result, there may not even be enough saturated fatty acids in the bloodstream to compensate for weight loss in athletes who have Type 2 diabetes. \n",
      " There is some debate as to what is wrong with Type @-@ 2 diabetes. \n",
      " = = Epidemiology = = \n",
      " According to epidemiologic studies, there have been over 3 @,@ 000 documented cases of Type @-@ 2 diabetes in the U.S. According to the Centers for Disease Control and Prevention ( CDC ), there have been 2 @,@ 062 hospitalizations per 1 @,@ 000 people as of 2011 for Type @-@ 2 diabetics. There have also been 18 hospitalizations per 1 @,@ 000 people as of 2011 for Type @-@ 2 diabetics. According to the World Health Organization ( World Health Organization ) there have been 2 @,@ 516 traffic accidents in\n",
      "------------------------------------------------------------------------\n",
      "------------------------------------------------------------------------\n",
      " = = = \n",
      " On February 21, 2007, it was announced that the band had entered talks about a recording deal with Polydor Records, one of their record label's parent companies. On February 27, it was reported that Bon Jovi's record deal was extended by six months. On March 9, it was reported that Bon Jovi's recording contract was due to expire on July 31, 2007, at the age of 33 years old. Bon Jovi's record deal with Polydor would not be renewed for another six months. Bon Jovi's official Facebook page states, “ We look forward to seeing what they ’ re up to ”, adding : \n",
      " It ’ ’ s amazing to work with them because they have so many different things to work on. It ’ s been such an honor to work with them. It ’ s been my dream come true to work with them. It ’ s great working with them and I think it ’ s exciting. ” \n",
      " On April 24, Bon Jovi announced that Bon Jovi @-@ produced songs from Bon Jovi's upcoming ninth studio album would be released on April 28, 2007.\n",
      "------------------------------------------------------------------------\n",
      "------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for i in generated_texts[10:20]:\n",
    "    print(i)\n",
    "    print('------------------------------------------------------------------------')\n",
    "    print('------------------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_gen = []\n",
    "for example in generated_texts:\n",
    "    if len(example) >= MAX_LENGTH:\n",
    "        cleaned_gen.append(example[:MAX_LENGTH])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9900\n"
     ]
    }
   ],
   "source": [
    "print(len(cleaned_gen))\n",
    "random.shuffle(cleaned_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " was cancelled due to technical troubles caused by a lackadaisical decision on the part of Warner Brothers to delay publication of the game. It was cancelled again on November 2, 2008 due to technical problems resulting from a shortage of space. It was re @-@ released on January 1, 2009 for Windows Vista and as part of Sony Computer Entertainment's ( Sony Computer Entertainment ) Greatest Hits series on December 19, 2007. \n",
      " In an interview in April 2010, Nintendo president Reggie Fils @-@ Aimé e\n"
     ]
    }
   ],
   "source": [
    "print(cleaned_gen[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "35000it [00:00, 2390267.03it/s]\n"
     ]
    }
   ],
   "source": [
    "cleaned_wiki_train = create_wiki_set(data_set_type='train',n=35000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11321\n",
      "[' = Valkyria Chronicles III = \\n Senjō no Valkyria 3 : <unk> Chronicles ( Japanese : 戦場のヴァルキュリア3 , lit . Valkyria of the Battlefield 3 ) , commonly referred to as Valkyria Chronicles III outside Japan , is a tactical role @-@ playing video game developed by Sega and Media.Vision for the PlayStation Portable . Released in January 2011 in Japan , it is the third game in the Valkyria series . Employing the same fusion of tactical and real @-@ time gameplay as its predecessors , the story runs paralle', \" The game began development in 2010 , carrying over a large portion of the work done on Valkyria Chronicles II . While it retained the standard features of the series , it also underwent multiple adjustments , such as making the game more forgiving for series newcomers . Character designer <unk> Honjou and composer Hitoshi Sakimoto both returned from previous entries , along with Valkyria Chronicles II director Takeshi Ozawa . A large team of writers handled the script . The game 's opening them\", \" It met with positive sales in Japan , and was praised by both Japanese and western critics . After release , it received downloadable content , along with an expanded edition in November of that year . It was also adapted into manga and an original video animation series . Due to low sales of Valkyria Chronicles II , Valkyria Chronicles III was not localized , but a fan translation compatible with the game 's expanded edition was released in 2014 . Media.Vision would return to the franchise wit\", ' = = Gameplay = = \\n As with previous <unk> Chronicles games , Valkyria Chronicles III is a tactical role @-@ playing game where players take control of a military unit and take part in missions against enemy forces . Stories are told through comic book @-@ like panels with animated character portraits , with characters speaking partially through voiced speech bubbles and partially through unvoiced text . The player progresses through a series of linear missions , gradually unlocked as maps that ']\n"
     ]
    }
   ],
   "source": [
    "print(len(cleaned_wiki_train))\n",
    "print(cleaned_wiki_train[:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/home/brody/school/w266/data/cleaned_generated_text_wn.data', 'wb') as f:\n",
    "    pickle.dump(cleaned_gen, f)\n",
    "with open('/home/brody/school/w266/data/cleaned_wiki_text_wn.data', 'wb') as f:\n",
    "    pickle.dump(cleaned_wiki_train, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/home/brody/school/w266/data/cleaned_generated_text_wn.data', 'rb') as f:\n",
    "    cleaned_gen = pickle.load(f)\n",
    "with open('/home/brody/school/w266/data/cleaned_wiki_text_wn.data', 'rb') as f:\n",
    "    cleaned_wiki_train = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9900\n"
     ]
    }
   ],
   "source": [
    "cleaned_wiki = cleaned_wiki_train[:len(cleaned_gen)]\n",
    "print(len(cleaned_wiki))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0 for human, 1 for bot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "wiki_train_labels = np.array([0]*(len(cleaned_wiki)-500) + [1]*(len(cleaned_gen)-500))\n",
    "wiki_val_labels = np.array([0]*500+[1]*500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_texts = cleaned_wiki[:-500] + cleaned_gen[:-500]\n",
    "val_texts = cleaned_wiki[-500:] + cleaned_gen[-500:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-24 20:56:23.354532: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-24 20:56:23.386498: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-24 20:56:23.386624: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-24 20:56:23.387046: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-07-24 20:56:23.387649: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-24 20:56:23.387753: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-24 20:56:23.387845: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-24 20:56:23.699745: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-24 20:56:23.699875: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-24 20:56:23.699969: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-24 20:56:23.700044: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 6247 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2080 SUPER, pci bus id: 0000:01:00.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "train_encodings = tokenizer(train_texts, truncation=True, padding=True, max_length=100, return_tensors='tf')\n",
    "valid_encodings = tokenizer(val_texts, truncation=True, padding=True, max_length=100, return_tensors='tf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at roberta-base were not used when initializing TFRobertaModel: ['lm_head']\n",
      "- This IS expected if you are initializing TFRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFRobertaModel were initialized from the model checkpoint at roberta-base.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " attention_mask_layer (InputLay  [(None, 100)]       0           []                               \n",
      " er)                                                                                              \n",
      "                                                                                                  \n",
      " input_ids_layer (InputLayer)   [(None, 100)]        0           []                               \n",
      "                                                                                                  \n",
      " tf_roberta_model (TFRobertaMod  TFBaseModelOutputWi  124645632  ['attention_mask_layer[0][0]',   \n",
      " el)                            thPoolingAndCrossAt               'input_ids_layer[0][0]']        \n",
      "                                tentions(last_hidde                                               \n",
      "                                n_state=(None, 100,                                               \n",
      "                                 768),                                                            \n",
      "                                 pooler_output=(Non                                               \n",
      "                                e, 768),                                                          \n",
      "                                 past_key_values=No                                               \n",
      "                                ne, hidden_states=N                                               \n",
      "                                one, attentions=Non                                               \n",
      "                                e, cross_attentions                                               \n",
      "                                =None)                                                            \n",
      "                                                                                                  \n",
      " hidden_layer (Dense)           (None, 150)          115350      ['tf_roberta_model[0][1]']       \n",
      "                                                                                                  \n",
      " dropout_37 (Dropout)           (None, 150)          0           ['hidden_layer[0][0]']           \n",
      "                                                                                                  \n",
      " classification_layer (Dense)   (None, 1)            151         ['dropout_37[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 124,761,133\n",
      "Trainable params: 124,761,133\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/2\n",
      "2350/2350 [==============================] - 241s 100ms/step - loss: 0.0216 - accuracy: 0.9924 - precision: 0.9905 - recall: 0.9944 - val_loss: 5.0150e-04 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 2/2\n",
      "2350/2350 [==============================] - 237s 101ms/step - loss: 0.0046 - accuracy: 0.9987 - precision: 0.9981 - recall: 0.9993 - val_loss: 7.7097e-06 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n"
     ]
    }
   ],
   "source": [
    "bert_model = build_base_roberta(learning_rate = 0.00001,\n",
    "                      dropout=0.35,\n",
    "                      hidden_size=150)\n",
    "bert_model.summary()\n",
    "bert_model_history = bert_model.fit([train_encodings.input_ids, train_encodings.attention_mask], \n",
    "                                                  wiki_train_labels,   \n",
    "                                                  validation_data=([valid_encodings.input_ids, valid_encodings.attention_mask], \n",
    "                                                  wiki_val_labels),    \n",
    "                                                  batch_size=8, \n",
    "                                                  epochs=2, shuffle=True,)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_plot(axs, history1, \n",
    "              y_lim_loss_lower=0.0, \n",
    "              y_lim_loss_upper=0.05,\n",
    "              y_lim_accuracy_lower=0.95, \n",
    "              y_lim_accuracy_upper=1,\n",
    "              model_1_name='model 1',\n",
    "              \n",
    "             ):\n",
    "    box = dict(facecolor='yellow', pad=5, alpha=0.2)\n",
    "\n",
    "    ax1 = axs[0]\n",
    "    ax1.plot(history1.history['loss'])\n",
    "    ax1.plot(history1.history['val_loss'])\n",
    "    ax1.set_title('loss - ' + model_1_name)\n",
    "    ax1.set_ylabel('loss', bbox=box)\n",
    "    ax1.set_ylim(y_lim_loss_lower, y_lim_loss_upper)\n",
    "\n",
    "    ax3 = axs[1]\n",
    "    ax3.set_title('accuracy - ' + model_1_name)\n",
    "    ax3.plot(history1.history['accuracy'])\n",
    "    ax3.plot(history1.history['val_accuracy'])\n",
    "    ax3.set_ylabel('accuracy', bbox=box)\n",
    "    ax3.set_ylim(y_lim_accuracy_lower, y_lim_accuracy_upper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1332x756 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axs = plt.subplots(2, 1)\n",
    "fig.subplots_adjust(left=0.2, wspace=0.6)\n",
    "make_plot(axs, \n",
    "          bert_model_history,\n",
    "         y_lim_accuracy_lower=0.95,\n",
    "         y_lim_accuracy_upper=1)\n",
    "\n",
    "fig.align_ylabels(axs)\n",
    "fig.set_size_inches(18.5, 10.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as encoder_layer_call_fn, encoder_layer_call_and_return_conditional_losses, pooler_layer_call_fn, pooler_layer_call_and_return_conditional_losses, embeddings_layer_call_fn while saving (showing 5 of 420). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://93e33ab8-d981-4ae0-9789-82ec4a24c090/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://93e33ab8-d981-4ae0-9789-82ec4a24c090/assets\n"
     ]
    }
   ],
   "source": [
    "with open('/home/brody/school/w266/baseline_roberta/best_baseline.data', 'wb') as f:\n",
    "    pickle.dump(bert_model, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as encoder_layer_call_fn, encoder_layer_call_and_return_conditional_losses, pooler_layer_call_fn, pooler_layer_call_and_return_conditional_losses, embeddings_layer_call_fn while saving (showing 5 of 420). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/brody/school/w266/baseline_roberta/keras_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/brody/school/w266/baseline_roberta/keras_model/assets\n"
     ]
    }
   ],
   "source": [
    "bert_model.save('/home/brody/school/w266/baseline_roberta/keras_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tweep Fake data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweep_val = pd.read_csv('/home/brody/school/w266/tweep_fake/validation.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>screen_name</th>\n",
       "      <th>text</th>\n",
       "      <th>account.type</th>\n",
       "      <th>class_type</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ahadsheriff</td>\n",
       "      <td>TIGHT, TIGHT, TIGHT, YEAH!!! https://t.co/wj3n...</td>\n",
       "      <td>human</td>\n",
       "      <td>human</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>narendramodi</td>\n",
       "      <td>India has millennia old relations with Oman. W...</td>\n",
       "      <td>human</td>\n",
       "      <td>human</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>jaden</td>\n",
       "      <td>Anxious Teenagers</td>\n",
       "      <td>human</td>\n",
       "      <td>human</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>JustinTrudeau</td>\n",
       "      <td>Our top priority is keeping Canadians safe. Wi...</td>\n",
       "      <td>human</td>\n",
       "      <td>human</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>imranyebot</td>\n",
       "      <td>nah bro You’re taking sis so much I’m just a g...</td>\n",
       "      <td>bot</td>\n",
       "      <td>others</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     screen_name                                               text  \\\n",
       "0    ahadsheriff  TIGHT, TIGHT, TIGHT, YEAH!!! https://t.co/wj3n...   \n",
       "1   narendramodi  India has millennia old relations with Oman. W...   \n",
       "2          jaden                                  Anxious Teenagers   \n",
       "3  JustinTrudeau  Our top priority is keeping Canadians safe. Wi...   \n",
       "4     imranyebot  nah bro You’re taking sis so much I’m just a g...   \n",
       "\n",
       "  account.type class_type  labels  \n",
       "0        human      human       0  \n",
       "1        human      human       0  \n",
       "2        human      human       0  \n",
       "3        human      human       0  \n",
       "4          bot     others       1  "
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweep_val.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "human     1150\n",
       "others     436\n",
       "rnn        370\n",
       "gpt2       346\n",
       "Name: class_type, dtype: int64"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweep_val['class_type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweep_val['labels'] = tweep_val.apply(lambda x: 0 if x['account.type']=='human' else 1, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     screen_name                                               text  \\\n",
      "0    ahadsheriff  TIGHT, TIGHT, TIGHT, YEAH!!! https://t.co/wj3n...   \n",
      "1   narendramodi  India has millennia old relations with Oman. W...   \n",
      "2          jaden                                  Anxious Teenagers   \n",
      "3  JustinTrudeau  Our top priority is keeping Canadians safe. Wi...   \n",
      "9         zawvrk                  @jpkayy yo this is not a bad idea   \n",
      "\n",
      "  account.type class_type  labels  \n",
      "0        human      human       0  \n",
      "1        human      human       0  \n",
      "2        human      human       0  \n",
      "3        human      human       0  \n",
      "9        human      human       0  \n"
     ]
    }
   ],
   "source": [
    "tweep_val_human = tweep_val[tweep_val['class_type'] == 'human']\n",
    "print(tweep_val_human.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweep_val_gpt = tweep_val[tweep_val['class_type'] == 'gpt2']\n",
    "tweep_val_gpt = pd.concat([tweep_val_gpt,tweep_val_human.iloc[:len(tweep_val_gpt)]])\n",
    "\n",
    "tweep_val_bot = tweep_val[tweep_val['labels'] == 1]\n",
    "tweep_val_bot = pd.concat([tweep_val_bot,tweep_val_human.iloc[:len(tweep_val_bot)]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweep_val_gpt_labels = tweep_val_gpt['labels'].to_numpy()\n",
    "tweep_val_bot_labels = tweep_val_bot['labels'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    346\n",
       "0    346\n",
       "Name: labels, dtype: int64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweep_val_gpt['labels'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    1152\n",
       "0    1150\n",
       "Name: labels, dtype: int64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweep_val_bot['labels'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweep_val_gpt_texts = tweep_val_gpt['text'].to_numpy().tolist()\n",
    "tweep_val_bot_texts = tweep_val_bot['text'].to_numpy().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweep_val_gpt_encodings = tokenizer(tweep_val_gpt_texts, truncation=True, padding=True, max_length=100, return_tensors='tf')\n",
    "tweep_val_bot_encodings = tokenizer(tweep_val_bot_texts, truncation=True, padding=True, max_length=100, return_tensors='tf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 4s 353ms/step - loss: 4.1230 - accuracy: 0.5014 - precision: 0.5007 - recall: 0.9942\n"
     ]
    }
   ],
   "source": [
    "results = bert_model.evaluate([tweep_val_gpt_encodings.input_ids, tweep_val_gpt_encodings.attention_mask], tweep_val_gpt_labels, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 7s 393ms/step - loss: 4.0393 - accuracy: 0.5048 - precision: 0.5026 - recall: 0.9965\n"
     ]
    }
   ],
   "source": [
    "results = bert_model.evaluate([tweep_val_bot_encodings.input_ids, tweep_val_bot_encodings.attention_mask], tweep_val_bot_labels, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 [==============================] - 4s 128ms/step\n"
     ]
    }
   ],
   "source": [
    "tweep_gpt_predictions = bert_model.predict([tweep_val_gpt_encodings.input_ids, tweep_val_gpt_encodings.attention_mask])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.9867058e-01],\n",
       "       [9.9666709e-01],\n",
       "       [9.9718827e-01],\n",
       "       [9.9996984e-01],\n",
       "       [9.9999142e-01],\n",
       "       [9.9913907e-01],\n",
       "       [9.9914086e-01],\n",
       "       [9.9998200e-01],\n",
       "       [9.9998605e-01],\n",
       "       [9.9999392e-01],\n",
       "       [9.9998891e-01],\n",
       "       [9.9998772e-01],\n",
       "       [9.9707174e-01],\n",
       "       [9.9774629e-01],\n",
       "       [9.9905878e-01],\n",
       "       [9.9547750e-01],\n",
       "       [9.9982601e-01],\n",
       "       [9.9998796e-01],\n",
       "       [9.9930954e-01],\n",
       "       [9.9612820e-01],\n",
       "       [9.9861240e-01],\n",
       "       [9.9950945e-01],\n",
       "       [9.9998033e-01],\n",
       "       [9.9972862e-01],\n",
       "       [9.9998534e-01],\n",
       "       [9.9881685e-01],\n",
       "       [9.9943668e-01],\n",
       "       [9.9838209e-01],\n",
       "       [9.9861610e-01],\n",
       "       [9.9963510e-01],\n",
       "       [9.9998474e-01],\n",
       "       [9.9861252e-01],\n",
       "       [9.6217507e-01],\n",
       "       [9.9851984e-01],\n",
       "       [9.9998534e-01],\n",
       "       [9.9997830e-01],\n",
       "       [9.9944276e-01],\n",
       "       [9.9998021e-01],\n",
       "       [9.9998450e-01],\n",
       "       [9.9943656e-01],\n",
       "       [9.9998343e-01],\n",
       "       [9.9669963e-01],\n",
       "       [9.9406910e-01],\n",
       "       [9.9990976e-01],\n",
       "       [9.9758708e-01],\n",
       "       [9.9947780e-01],\n",
       "       [9.9998403e-01],\n",
       "       [9.9805200e-01],\n",
       "       [9.9998784e-01],\n",
       "       [9.9357563e-01],\n",
       "       [9.9997675e-01],\n",
       "       [9.9970728e-01],\n",
       "       [9.9925369e-01],\n",
       "       [9.9998415e-01],\n",
       "       [9.9998176e-01],\n",
       "       [9.9590683e-01],\n",
       "       [9.9998236e-01],\n",
       "       [9.9291784e-01],\n",
       "       [9.9927050e-01],\n",
       "       [9.9997926e-01],\n",
       "       [9.9560404e-01],\n",
       "       [9.9934143e-01],\n",
       "       [9.9747950e-01],\n",
       "       [9.9997985e-01],\n",
       "       [9.9953973e-01],\n",
       "       [9.9999022e-01],\n",
       "       [9.9894315e-01],\n",
       "       [9.9999166e-01],\n",
       "       [9.9401891e-01],\n",
       "       [9.9681264e-01],\n",
       "       [9.9941957e-01],\n",
       "       [9.9813926e-01],\n",
       "       [9.9889225e-01],\n",
       "       [9.9999225e-01],\n",
       "       [9.9998641e-01],\n",
       "       [9.9850178e-01],\n",
       "       [9.8371625e-01],\n",
       "       [9.9764758e-01],\n",
       "       [9.9758589e-01],\n",
       "       [9.9829537e-01],\n",
       "       [9.9579144e-01],\n",
       "       [9.9974626e-01],\n",
       "       [9.9830186e-01],\n",
       "       [9.9998701e-01],\n",
       "       [9.9955362e-01],\n",
       "       [9.9899060e-01],\n",
       "       [9.9998569e-01],\n",
       "       [9.9650866e-01],\n",
       "       [9.9606848e-01],\n",
       "       [9.9971133e-01],\n",
       "       [9.9882799e-01],\n",
       "       [9.9993777e-01],\n",
       "       [9.9974412e-01],\n",
       "       [9.9926168e-01],\n",
       "       [9.9767250e-01],\n",
       "       [9.9998140e-01],\n",
       "       [9.9910432e-01],\n",
       "       [9.9839753e-01],\n",
       "       [9.9997485e-01],\n",
       "       [9.9892479e-01],\n",
       "       [9.9998975e-01],\n",
       "       [9.9998713e-01],\n",
       "       [9.9865097e-01],\n",
       "       [9.9397463e-01],\n",
       "       [9.9998093e-01],\n",
       "       [9.9283457e-01],\n",
       "       [9.9632794e-01],\n",
       "       [9.9998748e-01],\n",
       "       [9.9998772e-01],\n",
       "       [9.9833268e-01],\n",
       "       [9.9988770e-01],\n",
       "       [9.9998164e-01],\n",
       "       [9.9993265e-01],\n",
       "       [9.9998713e-01],\n",
       "       [9.9862373e-01],\n",
       "       [9.9856395e-01],\n",
       "       [9.9610496e-01],\n",
       "       [9.9896061e-01],\n",
       "       [9.9999022e-01],\n",
       "       [9.9951947e-01],\n",
       "       [9.9801528e-01],\n",
       "       [9.9204785e-01],\n",
       "       [9.9998724e-01],\n",
       "       [9.9879563e-01],\n",
       "       [9.9701154e-01],\n",
       "       [9.9973994e-01],\n",
       "       [9.9997616e-01],\n",
       "       [9.9998629e-01],\n",
       "       [9.9952209e-01],\n",
       "       [9.9839669e-01],\n",
       "       [9.9998558e-01],\n",
       "       [9.9998379e-01],\n",
       "       [9.9655187e-01],\n",
       "       [9.9720913e-01],\n",
       "       [9.9752790e-01],\n",
       "       [9.9478936e-01],\n",
       "       [9.9940050e-01],\n",
       "       [9.9998915e-01],\n",
       "       [9.9611580e-01],\n",
       "       [9.9999142e-01],\n",
       "       [9.9997663e-01],\n",
       "       [9.9951708e-01],\n",
       "       [9.9530751e-01],\n",
       "       [9.9998271e-01],\n",
       "       [9.9982506e-01],\n",
       "       [9.9859875e-01],\n",
       "       [9.9994600e-01],\n",
       "       [9.9998224e-01],\n",
       "       [9.9997413e-01],\n",
       "       [9.9964333e-01],\n",
       "       [9.8410851e-01],\n",
       "       [9.9998641e-01],\n",
       "       [9.9998879e-01],\n",
       "       [9.9932814e-01],\n",
       "       [9.9946135e-01],\n",
       "       [9.9696249e-01],\n",
       "       [9.9998796e-01],\n",
       "       [9.9998903e-01],\n",
       "       [9.9448133e-01],\n",
       "       [9.9980026e-01],\n",
       "       [9.9998868e-01],\n",
       "       [9.9998379e-01],\n",
       "       [9.9998057e-01],\n",
       "       [2.1336404e-05],\n",
       "       [9.8512393e-01],\n",
       "       [9.9999011e-01],\n",
       "       [9.9999332e-01],\n",
       "       [9.9998426e-01],\n",
       "       [9.9922931e-01],\n",
       "       [9.9998415e-01],\n",
       "       [9.9869341e-01],\n",
       "       [9.9523157e-01],\n",
       "       [9.9997890e-01],\n",
       "       [9.9956304e-01],\n",
       "       [9.9788398e-01],\n",
       "       [9.9997890e-01],\n",
       "       [9.9910921e-01],\n",
       "       [9.9806386e-01],\n",
       "       [9.9998403e-01],\n",
       "       [9.9998391e-01],\n",
       "       [9.9879491e-01],\n",
       "       [9.9999118e-01],\n",
       "       [9.9999285e-01],\n",
       "       [9.9998319e-01],\n",
       "       [9.9778616e-01],\n",
       "       [9.9964273e-01],\n",
       "       [9.9990296e-01],\n",
       "       [9.9707496e-01],\n",
       "       [9.9998927e-01],\n",
       "       [9.9809498e-01],\n",
       "       [9.9998438e-01],\n",
       "       [9.9740928e-01],\n",
       "       [9.9998641e-01],\n",
       "       [9.9998820e-01],\n",
       "       [9.9589121e-01],\n",
       "       [9.9999046e-01],\n",
       "       [9.9998522e-01],\n",
       "       [9.9997830e-01],\n",
       "       [9.9917918e-01],\n",
       "       [9.9713612e-01],\n",
       "       [9.9998605e-01],\n",
       "       [9.9998891e-01],\n",
       "       [9.8191637e-01],\n",
       "       [9.9590576e-01],\n",
       "       [9.9998474e-01],\n",
       "       [9.9786180e-01],\n",
       "       [9.9998558e-01],\n",
       "       [9.9554980e-01],\n",
       "       [9.9999464e-01],\n",
       "       [9.9997723e-01],\n",
       "       [9.9969494e-01],\n",
       "       [9.9874783e-01],\n",
       "       [9.9998820e-01],\n",
       "       [9.9853301e-01],\n",
       "       [9.9791294e-01],\n",
       "       [9.9999011e-01],\n",
       "       [9.9997938e-01],\n",
       "       [9.9105412e-01],\n",
       "       [9.9977630e-01],\n",
       "       [9.9496752e-01],\n",
       "       [9.9998760e-01],\n",
       "       [9.9996293e-01],\n",
       "       [9.9885690e-01],\n",
       "       [9.9991286e-01],\n",
       "       [9.9702162e-01],\n",
       "       [9.9820626e-01],\n",
       "       [9.9998891e-01],\n",
       "       [9.9766016e-01],\n",
       "       [9.9959713e-01],\n",
       "       [9.9625897e-01],\n",
       "       [9.9998009e-01],\n",
       "       [9.9910992e-01],\n",
       "       [9.9997818e-01],\n",
       "       [9.9998760e-01],\n",
       "       [9.9998975e-01],\n",
       "       [9.9954826e-01],\n",
       "       [9.9998188e-01],\n",
       "       [9.9727470e-01],\n",
       "       [9.9998856e-01],\n",
       "       [3.3969971e-04],\n",
       "       [9.9642652e-01],\n",
       "       [9.9830282e-01],\n",
       "       [9.9968719e-01],\n",
       "       [9.9997723e-01],\n",
       "       [9.9933451e-01],\n",
       "       [9.9949360e-01],\n",
       "       [9.9549568e-01],\n",
       "       [9.9998653e-01],\n",
       "       [9.9648833e-01],\n",
       "       [9.9998605e-01],\n",
       "       [9.9997950e-01],\n",
       "       [9.8920190e-01],\n",
       "       [9.9871683e-01],\n",
       "       [9.9998355e-01],\n",
       "       [9.9973506e-01],\n",
       "       [9.9998891e-01],\n",
       "       [9.9998105e-01],\n",
       "       [9.9830651e-01],\n",
       "       [9.9930143e-01],\n",
       "       [9.9998462e-01],\n",
       "       [9.9998105e-01],\n",
       "       [9.9960393e-01],\n",
       "       [9.9998450e-01],\n",
       "       [9.9998879e-01],\n",
       "       [9.9459827e-01],\n",
       "       [9.9960309e-01],\n",
       "       [9.9851102e-01],\n",
       "       [9.8311907e-01],\n",
       "       [9.8655415e-01],\n",
       "       [9.9579144e-01],\n",
       "       [9.9555439e-01],\n",
       "       [9.9890959e-01],\n",
       "       [9.9983132e-01],\n",
       "       [9.5429242e-01],\n",
       "       [9.9742019e-01],\n",
       "       [9.9585551e-01],\n",
       "       [9.9769574e-01],\n",
       "       [9.9847215e-01],\n",
       "       [9.9613106e-01],\n",
       "       [9.9999547e-01],\n",
       "       [9.9968719e-01],\n",
       "       [9.9196273e-01],\n",
       "       [9.9780875e-01],\n",
       "       [9.9997830e-01],\n",
       "       [9.9844474e-01],\n",
       "       [9.9844009e-01],\n",
       "       [9.9608022e-01],\n",
       "       [9.9941742e-01],\n",
       "       [9.9997485e-01],\n",
       "       [9.9999213e-01],\n",
       "       [9.9969029e-01],\n",
       "       [9.9498159e-01],\n",
       "       [9.9998915e-01],\n",
       "       [9.9998760e-01],\n",
       "       [9.9998868e-01],\n",
       "       [9.9880111e-01],\n",
       "       [9.9930418e-01],\n",
       "       [9.9694061e-01],\n",
       "       [9.9998593e-01],\n",
       "       [9.9946147e-01],\n",
       "       [9.9761742e-01],\n",
       "       [9.9997473e-01],\n",
       "       [9.9936754e-01],\n",
       "       [9.9552876e-01],\n",
       "       [9.9998820e-01],\n",
       "       [9.9998653e-01],\n",
       "       [9.9649918e-01],\n",
       "       [9.9086869e-01],\n",
       "       [9.9851447e-01],\n",
       "       [9.9999130e-01],\n",
       "       [9.9960262e-01],\n",
       "       [9.9999106e-01],\n",
       "       [9.9783319e-01],\n",
       "       [9.9999034e-01],\n",
       "       [9.9535275e-01],\n",
       "       [9.9980861e-01],\n",
       "       [9.9998677e-01],\n",
       "       [9.9999094e-01],\n",
       "       [9.9318463e-01],\n",
       "       [9.9953640e-01],\n",
       "       [9.9779475e-01],\n",
       "       [9.9988461e-01],\n",
       "       [9.9921644e-01],\n",
       "       [9.9998248e-01],\n",
       "       [9.9951899e-01],\n",
       "       [9.9984634e-01],\n",
       "       [9.8580223e-01],\n",
       "       [9.8290598e-01],\n",
       "       [9.8923802e-01],\n",
       "       [9.9897766e-01],\n",
       "       [9.9967718e-01],\n",
       "       [9.9999130e-01],\n",
       "       [9.9636567e-01],\n",
       "       [9.9821305e-01],\n",
       "       [9.9927968e-01],\n",
       "       [9.8971981e-01],\n",
       "       [9.9546790e-01],\n",
       "       [9.9980444e-01],\n",
       "       [9.9855167e-01],\n",
       "       [9.9856359e-01],\n",
       "       [9.9954635e-01],\n",
       "       [9.9997163e-01],\n",
       "       [9.9834788e-01],\n",
       "       [9.9998569e-01],\n",
       "       [9.9999034e-01],\n",
       "       [9.9998212e-01],\n",
       "       [9.9984670e-01],\n",
       "       [9.9994040e-01],\n",
       "       [9.9603051e-01],\n",
       "       [9.9998498e-01],\n",
       "       [9.9764258e-01],\n",
       "       [9.9997389e-01],\n",
       "       [9.9854195e-01],\n",
       "       [9.9933821e-01],\n",
       "       [9.9998260e-01],\n",
       "       [9.9998093e-01],\n",
       "       [9.5016915e-01],\n",
       "       [9.9620974e-01],\n",
       "       [9.9983764e-01],\n",
       "       [9.9853587e-01],\n",
       "       [9.9037874e-01],\n",
       "       [9.9437165e-01],\n",
       "       [9.9999189e-01],\n",
       "       [9.9839598e-01],\n",
       "       [9.9801111e-01],\n",
       "       [9.9956208e-01],\n",
       "       [9.7194856e-01],\n",
       "       [9.9211830e-01],\n",
       "       [9.9950886e-01],\n",
       "       [9.9906009e-01],\n",
       "       [9.9999237e-01],\n",
       "       [9.9156719e-01],\n",
       "       [9.9891198e-01],\n",
       "       [9.9951613e-01],\n",
       "       [9.9706739e-01],\n",
       "       [9.9942762e-01],\n",
       "       [9.9970526e-01],\n",
       "       [9.9996316e-01],\n",
       "       [9.9997354e-01],\n",
       "       [9.8848480e-01],\n",
       "       [9.9914157e-01],\n",
       "       [9.9999118e-01],\n",
       "       [9.9998748e-01],\n",
       "       [9.9994504e-01],\n",
       "       [9.8681670e-01],\n",
       "       [9.9943405e-01],\n",
       "       [9.9910396e-01],\n",
       "       [9.9964821e-01],\n",
       "       [9.9892151e-01],\n",
       "       [9.9997759e-01],\n",
       "       [9.9998462e-01],\n",
       "       [9.9998808e-01],\n",
       "       [9.9968410e-01],\n",
       "       [9.9983048e-01],\n",
       "       [9.9448895e-01],\n",
       "       [9.9999285e-01],\n",
       "       [9.9405718e-01],\n",
       "       [9.9636590e-01],\n",
       "       [9.9999332e-01],\n",
       "       [9.9389762e-01],\n",
       "       [9.9998665e-01],\n",
       "       [9.9844921e-01],\n",
       "       [9.9988937e-01],\n",
       "       [9.9838233e-01],\n",
       "       [9.9999177e-01],\n",
       "       [9.9964499e-01],\n",
       "       [9.9952853e-01],\n",
       "       [9.9880326e-01],\n",
       "       [9.8591286e-01],\n",
       "       [8.8365659e-06],\n",
       "       [9.9941301e-01],\n",
       "       [9.9952114e-01],\n",
       "       [9.9976522e-01],\n",
       "       [9.9970597e-01],\n",
       "       [9.9999237e-01],\n",
       "       [9.9998844e-01],\n",
       "       [9.9866462e-01],\n",
       "       [9.9873155e-01],\n",
       "       [9.9962270e-01],\n",
       "       [9.9997211e-01],\n",
       "       [9.9995708e-01],\n",
       "       [9.9999237e-01],\n",
       "       [9.9982339e-01],\n",
       "       [9.7708899e-01],\n",
       "       [9.9984062e-01],\n",
       "       [9.9981481e-01],\n",
       "       [9.9999237e-01],\n",
       "       [9.9769443e-01],\n",
       "       [9.9998474e-01],\n",
       "       [9.9976784e-01],\n",
       "       [9.9650049e-01],\n",
       "       [9.9999177e-01],\n",
       "       [9.9964285e-01],\n",
       "       [9.9984586e-01],\n",
       "       [9.9998152e-01],\n",
       "       [9.9785209e-01],\n",
       "       [9.9945182e-01],\n",
       "       [9.9059767e-01],\n",
       "       [9.9999058e-01],\n",
       "       [9.9997056e-01],\n",
       "       [9.9965692e-01],\n",
       "       [9.9946707e-01],\n",
       "       [9.9969220e-01],\n",
       "       [9.9979740e-01],\n",
       "       [9.9907291e-01],\n",
       "       [9.9998724e-01],\n",
       "       [9.9902427e-01],\n",
       "       [9.9976534e-01],\n",
       "       [9.9738222e-01],\n",
       "       [9.9936706e-01],\n",
       "       [9.9221474e-01],\n",
       "       [9.9999106e-01],\n",
       "       [9.9473971e-01],\n",
       "       [9.9603528e-01],\n",
       "       [9.9910283e-01],\n",
       "       [9.9998212e-01],\n",
       "       [9.9998617e-01],\n",
       "       [9.9927849e-01],\n",
       "       [9.9920875e-01],\n",
       "       [9.9640250e-01],\n",
       "       [9.9869150e-01],\n",
       "       [9.9878854e-01],\n",
       "       [9.9997902e-01],\n",
       "       [9.9395645e-01],\n",
       "       [9.9983048e-01],\n",
       "       [9.9997544e-01],\n",
       "       [9.9306774e-01],\n",
       "       [9.9936932e-01],\n",
       "       [9.9998915e-01],\n",
       "       [9.9774891e-01],\n",
       "       [9.9986446e-01],\n",
       "       [9.9997091e-01],\n",
       "       [9.9998116e-01],\n",
       "       [9.9834394e-01],\n",
       "       [9.9726510e-01],\n",
       "       [9.9852091e-01],\n",
       "       [9.9999309e-01],\n",
       "       [9.9421471e-01],\n",
       "       [9.9932170e-01],\n",
       "       [9.9996054e-01],\n",
       "       [9.9681407e-01],\n",
       "       [9.9369860e-01],\n",
       "       [9.9974173e-01],\n",
       "       [9.9771667e-01],\n",
       "       [9.9780089e-01],\n",
       "       [9.9998641e-01],\n",
       "       [9.9976188e-01],\n",
       "       [9.9999559e-01],\n",
       "       [9.9982661e-01],\n",
       "       [9.9844533e-01],\n",
       "       [9.9932015e-01],\n",
       "       [9.9967921e-01],\n",
       "       [9.9997592e-01],\n",
       "       [9.9866116e-01],\n",
       "       [9.9991894e-01],\n",
       "       [9.9966860e-01],\n",
       "       [9.9998760e-01],\n",
       "       [9.9898821e-01],\n",
       "       [9.9966466e-01],\n",
       "       [9.9998891e-01],\n",
       "       [9.9997139e-01],\n",
       "       [9.9972135e-01],\n",
       "       [9.9998820e-01],\n",
       "       [9.9413931e-01],\n",
       "       [9.9945623e-01],\n",
       "       [9.9955553e-01],\n",
       "       [8.9547475e-06],\n",
       "       [9.9975973e-01],\n",
       "       [9.9998462e-01],\n",
       "       [9.9626899e-01],\n",
       "       [9.9644738e-01],\n",
       "       [9.9999082e-01],\n",
       "       [9.9999225e-01],\n",
       "       [9.9863029e-01],\n",
       "       [9.9791938e-01],\n",
       "       [9.9883658e-01],\n",
       "       [9.9998891e-01],\n",
       "       [9.9998498e-01],\n",
       "       [9.9997556e-01],\n",
       "       [9.9992621e-01],\n",
       "       [9.9999452e-01],\n",
       "       [9.9017709e-01],\n",
       "       [9.9974650e-01],\n",
       "       [9.9933654e-01],\n",
       "       [9.9879289e-01],\n",
       "       [9.9130511e-01],\n",
       "       [9.9970216e-01],\n",
       "       [9.9953270e-01],\n",
       "       [9.9999261e-01],\n",
       "       [9.9990547e-01],\n",
       "       [9.9854445e-01],\n",
       "       [9.9999321e-01],\n",
       "       [9.9997580e-01],\n",
       "       [9.9998426e-01],\n",
       "       [9.9965584e-01],\n",
       "       [9.9999022e-01],\n",
       "       [9.9962938e-01],\n",
       "       [9.9953938e-01],\n",
       "       [9.9997175e-01],\n",
       "       [9.9947566e-01],\n",
       "       [9.9935788e-01],\n",
       "       [9.9911660e-01],\n",
       "       [9.9996626e-01],\n",
       "       [9.9997807e-01],\n",
       "       [9.9999440e-01],\n",
       "       [9.9640071e-01],\n",
       "       [9.9997282e-01],\n",
       "       [9.9446636e-01],\n",
       "       [9.9979836e-01],\n",
       "       [9.9998939e-01],\n",
       "       [9.9998856e-01],\n",
       "       [9.9829012e-01],\n",
       "       [9.9888092e-01],\n",
       "       [9.9959749e-01],\n",
       "       [9.9924964e-01],\n",
       "       [9.9997735e-01],\n",
       "       [9.9998975e-01],\n",
       "       [9.9982089e-01],\n",
       "       [9.9956304e-01],\n",
       "       [9.9859530e-01],\n",
       "       [9.9664754e-01],\n",
       "       [9.9926597e-01],\n",
       "       [9.9998868e-01],\n",
       "       [9.9707294e-01],\n",
       "       [9.9958760e-01],\n",
       "       [9.9998713e-01],\n",
       "       [9.9969125e-01],\n",
       "       [9.9851972e-01],\n",
       "       [9.9939847e-01],\n",
       "       [9.9777371e-01],\n",
       "       [9.9999404e-01],\n",
       "       [9.9900132e-01],\n",
       "       [9.9998546e-01],\n",
       "       [9.9891031e-01],\n",
       "       [9.9998438e-01],\n",
       "       [9.9999070e-01],\n",
       "       [9.9701345e-01],\n",
       "       [9.9750853e-01],\n",
       "       [9.9968195e-01],\n",
       "       [9.9987972e-01],\n",
       "       [9.9998713e-01],\n",
       "       [9.9998999e-01],\n",
       "       [9.9998736e-01],\n",
       "       [9.9929595e-01],\n",
       "       [9.9998605e-01],\n",
       "       [9.9907541e-01],\n",
       "       [9.9998927e-01],\n",
       "       [9.9751616e-01],\n",
       "       [9.9943191e-01],\n",
       "       [9.9783128e-01],\n",
       "       [9.9949145e-01],\n",
       "       [9.9865240e-01],\n",
       "       [9.9072194e-01],\n",
       "       [9.9906188e-01],\n",
       "       [9.9998915e-01],\n",
       "       [9.9947613e-01],\n",
       "       [9.9998283e-01],\n",
       "       [9.9999261e-01],\n",
       "       [9.9402493e-01],\n",
       "       [9.9999094e-01],\n",
       "       [9.9989915e-01],\n",
       "       [9.9821633e-01],\n",
       "       [7.4083187e-06],\n",
       "       [9.9890792e-01],\n",
       "       [9.9998772e-01],\n",
       "       [9.9912804e-01],\n",
       "       [9.9999177e-01],\n",
       "       [9.9999022e-01],\n",
       "       [9.9969769e-01],\n",
       "       [9.9809664e-01],\n",
       "       [9.9998116e-01],\n",
       "       [9.9922538e-01],\n",
       "       [9.9576664e-01],\n",
       "       [9.9868113e-01],\n",
       "       [9.9979609e-01],\n",
       "       [9.9999034e-01],\n",
       "       [9.9999142e-01],\n",
       "       [9.9997246e-01],\n",
       "       [9.9997950e-01],\n",
       "       [9.9790466e-01],\n",
       "       [9.9941552e-01],\n",
       "       [9.9719369e-01],\n",
       "       [9.9982637e-01],\n",
       "       [9.9960798e-01],\n",
       "       [9.9889082e-01],\n",
       "       [9.9998558e-01],\n",
       "       [9.9998069e-01],\n",
       "       [9.9998868e-01],\n",
       "       [9.9281836e-01],\n",
       "       [9.9799466e-01],\n",
       "       [9.9931490e-01],\n",
       "       [9.9766493e-01],\n",
       "       [9.9997950e-01],\n",
       "       [9.9938166e-01],\n",
       "       [9.9998021e-01],\n",
       "       [9.9817383e-01],\n",
       "       [9.9131525e-01],\n",
       "       [9.9972993e-01],\n",
       "       [9.9553972e-01],\n",
       "       [9.9998438e-01],\n",
       "       [9.9939740e-01],\n",
       "       [9.9911505e-01],\n",
       "       [9.9925214e-01],\n",
       "       [9.9935609e-01],\n",
       "       [9.9953568e-01],\n",
       "       [9.9998760e-01],\n",
       "       [9.9998868e-01],\n",
       "       [9.9819285e-01],\n",
       "       [9.9952483e-01],\n",
       "       [9.9999070e-01],\n",
       "       [9.9998534e-01],\n",
       "       [9.9148542e-01],\n",
       "       [9.9932837e-01],\n",
       "       [9.9794692e-01],\n",
       "       [9.8392636e-01],\n",
       "       [9.9707353e-01],\n",
       "       [9.9913210e-01],\n",
       "       [9.9998295e-01],\n",
       "       [9.9634945e-01],\n",
       "       [9.9189407e-01],\n",
       "       [9.9999321e-01],\n",
       "       [9.8000425e-01],\n",
       "       [9.9922764e-01],\n",
       "       [9.9997842e-01],\n",
       "       [9.9815661e-01],\n",
       "       [9.9912304e-01],\n",
       "       [9.9999249e-01],\n",
       "       [9.9988246e-01],\n",
       "       [9.9886179e-01],\n",
       "       [9.9876273e-01],\n",
       "       [9.9977988e-01],\n",
       "       [9.9978727e-01],\n",
       "       [9.9958342e-01],\n",
       "       [9.9998069e-01],\n",
       "       [9.9932992e-01],\n",
       "       [9.8311484e-01],\n",
       "       [9.9846399e-01],\n",
       "       [9.9181938e-01],\n",
       "       [9.9998260e-01],\n",
       "       [9.9881124e-01],\n",
       "       [9.9949920e-01],\n",
       "       [9.9873108e-01],\n",
       "       [9.9992406e-01],\n",
       "       [9.9965584e-01],\n",
       "       [9.9997902e-01],\n",
       "       [9.9816656e-01],\n",
       "       [9.9999380e-01],\n",
       "       [9.8523641e-01],\n",
       "       [9.9998176e-01],\n",
       "       [9.9997318e-01],\n",
       "       [9.9998093e-01],\n",
       "       [9.9954045e-01]], dtype=float32)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweep_gpt_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n",
       "array([[  3, 343],\n",
       "       [  2, 344]], dtype=int32)>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.math.confusion_matrix(tweep_val_gpt_labels, [0 if x < 0.5 else 1 for x in tweep_gpt_predictions])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 664\n",
      "692\n"
     ]
    }
   ],
   "source": [
    "zero = 0\n",
    "one = 0\n",
    "for i in tweep_gpt_predictions:\n",
    "    if i < 0.01:\n",
    "        zero += 1\n",
    "    elif i > 0.99:\n",
    "        one += 1\n",
    "print(zero, one)\n",
    "print(len(tweep_gpt_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cresci 2017 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_10765/1420282989.py:1: DtypeWarning: Columns (0) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  cresci_genuine = pd.read_csv(\"/home/brody/school/w266/cresci17/cresci-2017.csv/datasets_full.csv/genuine_accounts.csv/tweets.csv\",\n"
     ]
    }
   ],
   "source": [
    "cresci_genuine = pd.read_csv(\"/home/brody/school/w266/cresci17/cresci-2017.csv/datasets_full.csv/genuine_accounts.csv/tweets.csv\",\n",
    "                            encoding=\"latin_1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "cresci_genuine = cresci_genuine['text'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "cresci_spam = pd.read_csv(\"/home/brody/school/w266/cresci17/cresci-2017.csv/datasets_full.csv/traditional_spambots_1.csv/tweets.csv\",\n",
    "                            encoding=\"latin_1\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "cresci_spam = cresci_spam['text'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2839362\n",
      "145094\n"
     ]
    }
   ],
   "source": [
    "print(len(cresci_genuine))\n",
    "print(len(cresci_spam))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['The Newest Cleantech VC is August Ventures http://j.mp/1xeYF0 by @agoldfisher',\n",
       "       'New blog post: \\\\u0e04\\\\u0e25\\\\u0e34\\\\u0e1b\\\\u0e15\\\\u0e25\\\\u0e01 \\\\u0e02\\\\u0e2d\\\\u0e07\\\\u0e08\\\\u0e23\\\\u0e34\\\\u0e07 (SnowBoard-1) http://bit.ly/L7SEx',\n",
       "       'Know yourself and you will win all battles. Sun Tzu',\n",
       "       'NOOOSSAAA: achei um site que funciona pra ganhar #MaisFollowers - d\\\\xe1 certinho galera -> http://tinyurl.com/MaissFollowers',\n",
       "       \"Fui dormi' (eu s\\\\xf3 posto aki acordei/dormi -qq)\",\n",
       "       'Calling all Eniva Leaders!  We need to talk! http://bitly.com/OPlUT',\n",
       "       'CNDH pide protecci\\\\xf3n para dos periodistas http://tinyurl.com/y9d3kn4',\n",
       "       'PLAKINHA KI GANHEI DA LUH *--* http://bit.ly/TtllU',\n",
       "       'Forex Charts: The Relative Strength Index:  http://url4.eu/2xC7j',\n",
       "       'New Home Sales Are Not Getting Better: The media\\\\u2019s first reaction to the Commerce Department\\\\u2019s new home sales numb... http://bit.ly/ajNsyE'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.choice(cresci_spam,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "cresci_gen = np.random.choice(cresci_genuine,len(cresci_spam))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "145094"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cresci_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'@Shirleyyy17 lmfao Shirley !!'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cresci_gen[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.shuffle(cresci_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.shuffle(cresci_spam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "cresci_gen_train = cresci_gen[:-5000]\n",
    "cresci_gen_train = cresci_gen_train[~pd.isna(cresci_gen_train)].tolist()\n",
    "\n",
    "cresci_spam_train = cresci_spam[:-5000]\n",
    "cresci_spam_train = cresci_spam_train[~pd.isna(cresci_spam_train)].tolist()\n",
    "\n",
    "cresci_gen_val = cresci_gen[-5000:]\n",
    "cresci_gen_val = cresci_gen_val[~pd.isna(cresci_gen_val)].tolist()\n",
    "\n",
    "cresci_spam_val = cresci_spam[-5000:]\n",
    "cresci_spam_val = cresci_spam_val[~pd.isna(cresci_spam_val)].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'TLTs Pressuring Resistance: The iShares 20+ Yr T-Bond ETF (NYSE: TLT) continues to trade in a high-level\\\\u2026 http://bit.ly/cnopqv'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cresci_spam_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "cresci_train = cresci_gen_train + cresci_spam_train\n",
    "cresci_val = cresci_gen_val + cresci_spam_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "cresci_train_labels = np.array([0]*len(cresci_gen_train) + [1]*len(cresci_spam_train))\n",
    "cresci_val_labels = np.array([0]*len(cresci_gen_val) + [1]*len(cresci_spam_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "cresci_train_encodings = tokenizer(cresci_train, truncation=True, padding=True, max_length=100, return_tensors='tf')\n",
    "cresci_val_encodings = tokenizer(cresci_val, truncation=True, padding=True, max_length=100, return_tensors='tf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at roberta-base were not used when initializing TFRobertaModel: ['lm_head']\n",
      "- This IS expected if you are initializing TFRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFRobertaModel were initialized from the model checkpoint at roberta-base.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "34945/34945 [==============================] - 3833s 109ms/step - loss: 0.0840 - accuracy: 0.9708 - precision_4: 0.9806 - recall_4: 0.9607 - val_loss: 0.0683 - val_accuracy: 0.9750 - val_precision_4: 0.9710 - val_recall_4: 0.9792\n",
      "Epoch 2/3\n",
      "34945/34945 [==============================] - 3843s 110ms/step - loss: 0.0554 - accuracy: 0.9809 - precision_4: 0.9872 - recall_4: 0.9745 - val_loss: 0.0677 - val_accuracy: 0.9822 - val_precision_4: 0.9861 - val_recall_4: 0.9782\n",
      "Epoch 3/3\n",
      "34945/34945 [==============================] - 3844s 110ms/step - loss: 0.0416 - accuracy: 0.9859 - precision_4: 0.9901 - recall_4: 0.9817 - val_loss: 0.0722 - val_accuracy: 0.9755 - val_precision_4: 0.9639 - val_recall_4: 0.9880\n"
     ]
    }
   ],
   "source": [
    "cresci_model = build_base_roberta(learning_rate = 0.00001,\n",
    "                      dropout=0.3,\n",
    "                      hidden_size=300)\n",
    "cresci_model_history = cresci_model.fit([cresci_train_encodings.input_ids, cresci_train_encodings.attention_mask], \n",
    "                                                  cresci_train_labels,   \n",
    "                                                  validation_data=([cresci_val_encodings.input_ids, cresci_val_encodings.attention_mask], \n",
    "                                                  cresci_val_labels),    \n",
    "                                                  batch_size=8, \n",
    "                                                  epochs=3, shuffle=True,)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/home/brody/school/w266/cresci_roberta/cresci.data', 'wb') as f:\n",
    "    pickle.dump(cresci_model, f)\n",
    "bert_model.save('/home/brody/school/w266/cresci_roberta/keras_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 2s 350ms/step - loss: 1.6950 - accuracy: 0.5101 - precision_4: 0.5245 - recall_4: 0.2168\n"
     ]
    }
   ],
   "source": [
    "results = cresci_model.evaluate([tweep_val_gpt_encodings.input_ids, tweep_val_gpt_encodings.attention_mask], tweep_val_gpt_labels, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 7s 393ms/step - loss: 1.6745 - accuracy: 0.5521 - precision_4: 0.6184 - recall_4: 0.2743\n"
     ]
    }
   ],
   "source": [
    "results = cresci_model.evaluate([tweep_val_bot_encodings.input_ids, tweep_val_bot_encodings.attention_mask], tweep_val_bot_labels, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72/72 [==============================] - 11s 130ms/step\n"
     ]
    }
   ],
   "source": [
    "cresci_predict_tweep = cresci_model.predict([tweep_val_bot_encodings.input_ids, tweep_val_bot_encodings.attention_mask])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpt_binary = [0 if x < 0.5 else 1 for x in cresci_predict_tweep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " ...]"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cpt_binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n",
       "array([[955, 195],\n",
       "       [836, 316]], dtype=int32)>"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.math.confusion_matrix(tweep_val_bot_labels, cpt_binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpt_pred_true = list(zip(cpt_binary, tweep_val_bot_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_case = {}\n",
    "\n",
    "for index, i in enumerate(cpt_pred_true):\n",
    "    if i in prediction_case:\n",
    "        prediction_case[i].append(index)\n",
    "    else:\n",
    "        prediction_case[i] = [index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(0, 1): [0,\n",
       "  2,\n",
       "  3,\n",
       "  4,\n",
       "  5,\n",
       "  6,\n",
       "  8,\n",
       "  9,\n",
       "  10,\n",
       "  11,\n",
       "  12,\n",
       "  14,\n",
       "  15,\n",
       "  16,\n",
       "  17,\n",
       "  18,\n",
       "  19,\n",
       "  20,\n",
       "  21,\n",
       "  23,\n",
       "  24,\n",
       "  25,\n",
       "  26,\n",
       "  27,\n",
       "  28,\n",
       "  29,\n",
       "  30,\n",
       "  31,\n",
       "  32,\n",
       "  33,\n",
       "  34,\n",
       "  37,\n",
       "  38,\n",
       "  42,\n",
       "  43,\n",
       "  44,\n",
       "  45,\n",
       "  46,\n",
       "  49,\n",
       "  50,\n",
       "  52,\n",
       "  54,\n",
       "  55,\n",
       "  56,\n",
       "  58,\n",
       "  60,\n",
       "  61,\n",
       "  63,\n",
       "  65,\n",
       "  66,\n",
       "  67,\n",
       "  68,\n",
       "  69,\n",
       "  72,\n",
       "  73,\n",
       "  75,\n",
       "  76,\n",
       "  79,\n",
       "  80,\n",
       "  81,\n",
       "  82,\n",
       "  87,\n",
       "  88,\n",
       "  89,\n",
       "  90,\n",
       "  91,\n",
       "  92,\n",
       "  93,\n",
       "  94,\n",
       "  96,\n",
       "  97,\n",
       "  99,\n",
       "  100,\n",
       "  101,\n",
       "  102,\n",
       "  103,\n",
       "  104,\n",
       "  105,\n",
       "  106,\n",
       "  107,\n",
       "  108,\n",
       "  112,\n",
       "  113,\n",
       "  115,\n",
       "  116,\n",
       "  117,\n",
       "  118,\n",
       "  120,\n",
       "  121,\n",
       "  122,\n",
       "  123,\n",
       "  124,\n",
       "  125,\n",
       "  126,\n",
       "  127,\n",
       "  131,\n",
       "  132,\n",
       "  133,\n",
       "  135,\n",
       "  136,\n",
       "  137,\n",
       "  139,\n",
       "  142,\n",
       "  144,\n",
       "  146,\n",
       "  147,\n",
       "  148,\n",
       "  149,\n",
       "  150,\n",
       "  152,\n",
       "  155,\n",
       "  156,\n",
       "  158,\n",
       "  159,\n",
       "  160,\n",
       "  161,\n",
       "  162,\n",
       "  164,\n",
       "  165,\n",
       "  167,\n",
       "  169,\n",
       "  170,\n",
       "  171,\n",
       "  172,\n",
       "  173,\n",
       "  174,\n",
       "  175,\n",
       "  179,\n",
       "  180,\n",
       "  182,\n",
       "  184,\n",
       "  185,\n",
       "  187,\n",
       "  189,\n",
       "  190,\n",
       "  191,\n",
       "  192,\n",
       "  193,\n",
       "  194,\n",
       "  195,\n",
       "  196,\n",
       "  197,\n",
       "  199,\n",
       "  201,\n",
       "  203,\n",
       "  205,\n",
       "  206,\n",
       "  207,\n",
       "  209,\n",
       "  212,\n",
       "  214,\n",
       "  215,\n",
       "  217,\n",
       "  218,\n",
       "  219,\n",
       "  220,\n",
       "  221,\n",
       "  222,\n",
       "  224,\n",
       "  225,\n",
       "  226,\n",
       "  227,\n",
       "  228,\n",
       "  229,\n",
       "  232,\n",
       "  233,\n",
       "  235,\n",
       "  237,\n",
       "  238,\n",
       "  239,\n",
       "  241,\n",
       "  242,\n",
       "  243,\n",
       "  244,\n",
       "  245,\n",
       "  246,\n",
       "  248,\n",
       "  249,\n",
       "  251,\n",
       "  252,\n",
       "  253,\n",
       "  254,\n",
       "  256,\n",
       "  257,\n",
       "  258,\n",
       "  259,\n",
       "  260,\n",
       "  262,\n",
       "  266,\n",
       "  267,\n",
       "  270,\n",
       "  274,\n",
       "  279,\n",
       "  282,\n",
       "  283,\n",
       "  286,\n",
       "  287,\n",
       "  289,\n",
       "  290,\n",
       "  291,\n",
       "  292,\n",
       "  293,\n",
       "  295,\n",
       "  296,\n",
       "  297,\n",
       "  298,\n",
       "  301,\n",
       "  302,\n",
       "  303,\n",
       "  304,\n",
       "  305,\n",
       "  306,\n",
       "  307,\n",
       "  308,\n",
       "  309,\n",
       "  312,\n",
       "  313,\n",
       "  314,\n",
       "  316,\n",
       "  317,\n",
       "  318,\n",
       "  319,\n",
       "  320,\n",
       "  321,\n",
       "  322,\n",
       "  323,\n",
       "  324,\n",
       "  326,\n",
       "  327,\n",
       "  328,\n",
       "  330,\n",
       "  331,\n",
       "  335,\n",
       "  336,\n",
       "  337,\n",
       "  339,\n",
       "  340,\n",
       "  341,\n",
       "  342,\n",
       "  344,\n",
       "  346,\n",
       "  347,\n",
       "  349,\n",
       "  352,\n",
       "  353,\n",
       "  354,\n",
       "  355,\n",
       "  358,\n",
       "  359,\n",
       "  360,\n",
       "  361,\n",
       "  362,\n",
       "  364,\n",
       "  365,\n",
       "  367,\n",
       "  368,\n",
       "  369,\n",
       "  371,\n",
       "  372,\n",
       "  373,\n",
       "  374,\n",
       "  375,\n",
       "  376,\n",
       "  377,\n",
       "  379,\n",
       "  381,\n",
       "  382,\n",
       "  383,\n",
       "  384,\n",
       "  385,\n",
       "  387,\n",
       "  388,\n",
       "  389,\n",
       "  390,\n",
       "  391,\n",
       "  392,\n",
       "  393,\n",
       "  395,\n",
       "  396,\n",
       "  397,\n",
       "  399,\n",
       "  400,\n",
       "  401,\n",
       "  403,\n",
       "  404,\n",
       "  405,\n",
       "  406,\n",
       "  407,\n",
       "  408,\n",
       "  409,\n",
       "  410,\n",
       "  411,\n",
       "  412,\n",
       "  413,\n",
       "  414,\n",
       "  415,\n",
       "  416,\n",
       "  418,\n",
       "  419,\n",
       "  421,\n",
       "  422,\n",
       "  423,\n",
       "  424,\n",
       "  426,\n",
       "  427,\n",
       "  428,\n",
       "  429,\n",
       "  430,\n",
       "  432,\n",
       "  433,\n",
       "  435,\n",
       "  436,\n",
       "  437,\n",
       "  438,\n",
       "  440,\n",
       "  441,\n",
       "  442,\n",
       "  443,\n",
       "  444,\n",
       "  445,\n",
       "  446,\n",
       "  447,\n",
       "  448,\n",
       "  449,\n",
       "  450,\n",
       "  451,\n",
       "  452,\n",
       "  453,\n",
       "  454,\n",
       "  455,\n",
       "  456,\n",
       "  457,\n",
       "  458,\n",
       "  459,\n",
       "  460,\n",
       "  461,\n",
       "  463,\n",
       "  464,\n",
       "  465,\n",
       "  466,\n",
       "  468,\n",
       "  469,\n",
       "  470,\n",
       "  471,\n",
       "  473,\n",
       "  474,\n",
       "  475,\n",
       "  477,\n",
       "  478,\n",
       "  479,\n",
       "  482,\n",
       "  483,\n",
       "  484,\n",
       "  485,\n",
       "  486,\n",
       "  488,\n",
       "  490,\n",
       "  491,\n",
       "  492,\n",
       "  494,\n",
       "  495,\n",
       "  496,\n",
       "  497,\n",
       "  498,\n",
       "  499,\n",
       "  500,\n",
       "  501,\n",
       "  502,\n",
       "  503,\n",
       "  505,\n",
       "  506,\n",
       "  509,\n",
       "  511,\n",
       "  512,\n",
       "  513,\n",
       "  514,\n",
       "  515,\n",
       "  516,\n",
       "  517,\n",
       "  518,\n",
       "  520,\n",
       "  521,\n",
       "  522,\n",
       "  525,\n",
       "  527,\n",
       "  528,\n",
       "  529,\n",
       "  530,\n",
       "  532,\n",
       "  533,\n",
       "  534,\n",
       "  535,\n",
       "  536,\n",
       "  539,\n",
       "  542,\n",
       "  544,\n",
       "  545,\n",
       "  546,\n",
       "  547,\n",
       "  549,\n",
       "  550,\n",
       "  551,\n",
       "  552,\n",
       "  553,\n",
       "  554,\n",
       "  555,\n",
       "  556,\n",
       "  557,\n",
       "  558,\n",
       "  559,\n",
       "  562,\n",
       "  563,\n",
       "  564,\n",
       "  565,\n",
       "  566,\n",
       "  567,\n",
       "  571,\n",
       "  572,\n",
       "  573,\n",
       "  574,\n",
       "  577,\n",
       "  578,\n",
       "  581,\n",
       "  582,\n",
       "  584,\n",
       "  585,\n",
       "  586,\n",
       "  587,\n",
       "  588,\n",
       "  590,\n",
       "  591,\n",
       "  592,\n",
       "  594,\n",
       "  595,\n",
       "  596,\n",
       "  597,\n",
       "  599,\n",
       "  603,\n",
       "  604,\n",
       "  605,\n",
       "  606,\n",
       "  607,\n",
       "  610,\n",
       "  612,\n",
       "  613,\n",
       "  614,\n",
       "  615,\n",
       "  616,\n",
       "  618,\n",
       "  619,\n",
       "  620,\n",
       "  622,\n",
       "  623,\n",
       "  625,\n",
       "  626,\n",
       "  627,\n",
       "  628,\n",
       "  629,\n",
       "  630,\n",
       "  631,\n",
       "  632,\n",
       "  633,\n",
       "  635,\n",
       "  636,\n",
       "  637,\n",
       "  638,\n",
       "  639,\n",
       "  640,\n",
       "  643,\n",
       "  646,\n",
       "  648,\n",
       "  649,\n",
       "  650,\n",
       "  652,\n",
       "  654,\n",
       "  655,\n",
       "  656,\n",
       "  657,\n",
       "  658,\n",
       "  659,\n",
       "  660,\n",
       "  662,\n",
       "  663,\n",
       "  669,\n",
       "  671,\n",
       "  672,\n",
       "  673,\n",
       "  674,\n",
       "  675,\n",
       "  676,\n",
       "  677,\n",
       "  678,\n",
       "  679,\n",
       "  680,\n",
       "  681,\n",
       "  682,\n",
       "  683,\n",
       "  685,\n",
       "  686,\n",
       "  687,\n",
       "  688,\n",
       "  689,\n",
       "  690,\n",
       "  692,\n",
       "  693,\n",
       "  696,\n",
       "  697,\n",
       "  698,\n",
       "  699,\n",
       "  700,\n",
       "  702,\n",
       "  704,\n",
       "  706,\n",
       "  707,\n",
       "  709,\n",
       "  710,\n",
       "  711,\n",
       "  714,\n",
       "  715,\n",
       "  716,\n",
       "  717,\n",
       "  718,\n",
       "  719,\n",
       "  720,\n",
       "  721,\n",
       "  722,\n",
       "  723,\n",
       "  726,\n",
       "  727,\n",
       "  728,\n",
       "  729,\n",
       "  731,\n",
       "  732,\n",
       "  733,\n",
       "  734,\n",
       "  735,\n",
       "  739,\n",
       "  740,\n",
       "  741,\n",
       "  742,\n",
       "  743,\n",
       "  744,\n",
       "  746,\n",
       "  747,\n",
       "  748,\n",
       "  749,\n",
       "  750,\n",
       "  751,\n",
       "  752,\n",
       "  754,\n",
       "  755,\n",
       "  756,\n",
       "  757,\n",
       "  758,\n",
       "  759,\n",
       "  760,\n",
       "  761,\n",
       "  762,\n",
       "  763,\n",
       "  764,\n",
       "  765,\n",
       "  766,\n",
       "  767,\n",
       "  768,\n",
       "  769,\n",
       "  770,\n",
       "  773,\n",
       "  774,\n",
       "  775,\n",
       "  776,\n",
       "  780,\n",
       "  781,\n",
       "  782,\n",
       "  783,\n",
       "  784,\n",
       "  785,\n",
       "  786,\n",
       "  787,\n",
       "  788,\n",
       "  789,\n",
       "  790,\n",
       "  792,\n",
       "  794,\n",
       "  795,\n",
       "  796,\n",
       "  797,\n",
       "  799,\n",
       "  801,\n",
       "  802,\n",
       "  804,\n",
       "  806,\n",
       "  808,\n",
       "  811,\n",
       "  812,\n",
       "  813,\n",
       "  816,\n",
       "  817,\n",
       "  818,\n",
       "  819,\n",
       "  821,\n",
       "  822,\n",
       "  823,\n",
       "  824,\n",
       "  826,\n",
       "  828,\n",
       "  831,\n",
       "  834,\n",
       "  835,\n",
       "  836,\n",
       "  838,\n",
       "  840,\n",
       "  841,\n",
       "  842,\n",
       "  844,\n",
       "  845,\n",
       "  846,\n",
       "  847,\n",
       "  848,\n",
       "  849,\n",
       "  850,\n",
       "  851,\n",
       "  853,\n",
       "  854,\n",
       "  857,\n",
       "  860,\n",
       "  861,\n",
       "  863,\n",
       "  864,\n",
       "  867,\n",
       "  868,\n",
       "  869,\n",
       "  871,\n",
       "  872,\n",
       "  875,\n",
       "  876,\n",
       "  877,\n",
       "  879,\n",
       "  880,\n",
       "  881,\n",
       "  883,\n",
       "  884,\n",
       "  885,\n",
       "  886,\n",
       "  887,\n",
       "  888,\n",
       "  890,\n",
       "  891,\n",
       "  893,\n",
       "  894,\n",
       "  895,\n",
       "  896,\n",
       "  897,\n",
       "  899,\n",
       "  902,\n",
       "  904,\n",
       "  906,\n",
       "  907,\n",
       "  908,\n",
       "  910,\n",
       "  911,\n",
       "  912,\n",
       "  913,\n",
       "  915,\n",
       "  916,\n",
       "  917,\n",
       "  919,\n",
       "  922,\n",
       "  923,\n",
       "  924,\n",
       "  925,\n",
       "  926,\n",
       "  928,\n",
       "  929,\n",
       "  930,\n",
       "  931,\n",
       "  932,\n",
       "  933,\n",
       "  934,\n",
       "  935,\n",
       "  936,\n",
       "  937,\n",
       "  939,\n",
       "  940,\n",
       "  941,\n",
       "  942,\n",
       "  945,\n",
       "  947,\n",
       "  949,\n",
       "  950,\n",
       "  951,\n",
       "  952,\n",
       "  953,\n",
       "  954,\n",
       "  956,\n",
       "  957,\n",
       "  961,\n",
       "  962,\n",
       "  963,\n",
       "  964,\n",
       "  965,\n",
       "  966,\n",
       "  969,\n",
       "  970,\n",
       "  971,\n",
       "  972,\n",
       "  973,\n",
       "  974,\n",
       "  975,\n",
       "  976,\n",
       "  977,\n",
       "  978,\n",
       "  979,\n",
       "  980,\n",
       "  981,\n",
       "  983,\n",
       "  985,\n",
       "  987,\n",
       "  988,\n",
       "  989,\n",
       "  990,\n",
       "  991,\n",
       "  992,\n",
       "  993,\n",
       "  994,\n",
       "  996,\n",
       "  998,\n",
       "  999,\n",
       "  1001,\n",
       "  1003,\n",
       "  1006,\n",
       "  1008,\n",
       "  1009,\n",
       "  1010,\n",
       "  1011,\n",
       "  1012,\n",
       "  1013,\n",
       "  1014,\n",
       "  1015,\n",
       "  1016,\n",
       "  1017,\n",
       "  1020,\n",
       "  1022,\n",
       "  1023,\n",
       "  1024,\n",
       "  1025,\n",
       "  1026,\n",
       "  1027,\n",
       "  1028,\n",
       "  1029,\n",
       "  1030,\n",
       "  1031,\n",
       "  1033,\n",
       "  1034,\n",
       "  1036,\n",
       "  1037,\n",
       "  1038,\n",
       "  1039,\n",
       "  1041,\n",
       "  1042,\n",
       "  1043,\n",
       "  1044,\n",
       "  1045,\n",
       "  1046,\n",
       "  1047,\n",
       "  1048,\n",
       "  1049,\n",
       "  1051,\n",
       "  1053,\n",
       "  1054,\n",
       "  1055,\n",
       "  1057,\n",
       "  1058,\n",
       "  1059,\n",
       "  1060,\n",
       "  1063,\n",
       "  1064,\n",
       "  1065,\n",
       "  1067,\n",
       "  1068,\n",
       "  1069,\n",
       "  1070,\n",
       "  1071,\n",
       "  1072,\n",
       "  1075,\n",
       "  1077,\n",
       "  1078,\n",
       "  1081,\n",
       "  1082,\n",
       "  1084,\n",
       "  1086,\n",
       "  1088,\n",
       "  1089,\n",
       "  1090,\n",
       "  1091,\n",
       "  1092,\n",
       "  1094,\n",
       "  1095,\n",
       "  1096,\n",
       "  1097,\n",
       "  1098,\n",
       "  1101,\n",
       "  1102,\n",
       "  1103,\n",
       "  1106,\n",
       "  1107,\n",
       "  1109,\n",
       "  1111,\n",
       "  1112,\n",
       "  1114,\n",
       "  1116,\n",
       "  1117,\n",
       "  1118,\n",
       "  1119,\n",
       "  1121,\n",
       "  1122,\n",
       "  1123,\n",
       "  1124,\n",
       "  1125,\n",
       "  1127,\n",
       "  1128,\n",
       "  1129,\n",
       "  1130,\n",
       "  1131,\n",
       "  1132,\n",
       "  1134,\n",
       "  1135,\n",
       "  1136,\n",
       "  1137,\n",
       "  1140,\n",
       "  1141,\n",
       "  1142,\n",
       "  1144,\n",
       "  1146,\n",
       "  1148,\n",
       "  1149,\n",
       "  1151],\n",
       " (1, 1): [1,\n",
       "  7,\n",
       "  13,\n",
       "  22,\n",
       "  35,\n",
       "  36,\n",
       "  39,\n",
       "  40,\n",
       "  41,\n",
       "  47,\n",
       "  48,\n",
       "  51,\n",
       "  53,\n",
       "  57,\n",
       "  59,\n",
       "  62,\n",
       "  64,\n",
       "  70,\n",
       "  71,\n",
       "  74,\n",
       "  77,\n",
       "  78,\n",
       "  83,\n",
       "  84,\n",
       "  85,\n",
       "  86,\n",
       "  95,\n",
       "  98,\n",
       "  109,\n",
       "  110,\n",
       "  111,\n",
       "  114,\n",
       "  119,\n",
       "  128,\n",
       "  129,\n",
       "  130,\n",
       "  134,\n",
       "  138,\n",
       "  140,\n",
       "  141,\n",
       "  143,\n",
       "  145,\n",
       "  151,\n",
       "  153,\n",
       "  154,\n",
       "  157,\n",
       "  163,\n",
       "  166,\n",
       "  168,\n",
       "  176,\n",
       "  177,\n",
       "  178,\n",
       "  181,\n",
       "  183,\n",
       "  186,\n",
       "  188,\n",
       "  198,\n",
       "  200,\n",
       "  202,\n",
       "  204,\n",
       "  208,\n",
       "  210,\n",
       "  211,\n",
       "  213,\n",
       "  216,\n",
       "  223,\n",
       "  230,\n",
       "  231,\n",
       "  234,\n",
       "  236,\n",
       "  240,\n",
       "  247,\n",
       "  250,\n",
       "  255,\n",
       "  261,\n",
       "  263,\n",
       "  264,\n",
       "  265,\n",
       "  268,\n",
       "  269,\n",
       "  271,\n",
       "  272,\n",
       "  273,\n",
       "  275,\n",
       "  276,\n",
       "  277,\n",
       "  278,\n",
       "  280,\n",
       "  281,\n",
       "  284,\n",
       "  285,\n",
       "  288,\n",
       "  294,\n",
       "  299,\n",
       "  300,\n",
       "  310,\n",
       "  311,\n",
       "  315,\n",
       "  325,\n",
       "  329,\n",
       "  332,\n",
       "  333,\n",
       "  334,\n",
       "  338,\n",
       "  343,\n",
       "  345,\n",
       "  348,\n",
       "  350,\n",
       "  351,\n",
       "  356,\n",
       "  357,\n",
       "  363,\n",
       "  366,\n",
       "  370,\n",
       "  378,\n",
       "  380,\n",
       "  386,\n",
       "  394,\n",
       "  398,\n",
       "  402,\n",
       "  417,\n",
       "  420,\n",
       "  425,\n",
       "  431,\n",
       "  434,\n",
       "  439,\n",
       "  462,\n",
       "  467,\n",
       "  472,\n",
       "  476,\n",
       "  480,\n",
       "  481,\n",
       "  487,\n",
       "  489,\n",
       "  493,\n",
       "  504,\n",
       "  507,\n",
       "  508,\n",
       "  510,\n",
       "  519,\n",
       "  523,\n",
       "  524,\n",
       "  526,\n",
       "  531,\n",
       "  537,\n",
       "  538,\n",
       "  540,\n",
       "  541,\n",
       "  543,\n",
       "  548,\n",
       "  560,\n",
       "  561,\n",
       "  568,\n",
       "  569,\n",
       "  570,\n",
       "  575,\n",
       "  576,\n",
       "  579,\n",
       "  580,\n",
       "  583,\n",
       "  589,\n",
       "  593,\n",
       "  598,\n",
       "  600,\n",
       "  601,\n",
       "  602,\n",
       "  608,\n",
       "  609,\n",
       "  611,\n",
       "  617,\n",
       "  621,\n",
       "  624,\n",
       "  634,\n",
       "  641,\n",
       "  642,\n",
       "  644,\n",
       "  645,\n",
       "  647,\n",
       "  651,\n",
       "  653,\n",
       "  661,\n",
       "  664,\n",
       "  665,\n",
       "  666,\n",
       "  667,\n",
       "  668,\n",
       "  670,\n",
       "  684,\n",
       "  691,\n",
       "  694,\n",
       "  695,\n",
       "  701,\n",
       "  703,\n",
       "  705,\n",
       "  708,\n",
       "  712,\n",
       "  713,\n",
       "  724,\n",
       "  725,\n",
       "  730,\n",
       "  736,\n",
       "  737,\n",
       "  738,\n",
       "  745,\n",
       "  753,\n",
       "  771,\n",
       "  772,\n",
       "  777,\n",
       "  778,\n",
       "  779,\n",
       "  791,\n",
       "  793,\n",
       "  798,\n",
       "  800,\n",
       "  803,\n",
       "  805,\n",
       "  807,\n",
       "  809,\n",
       "  810,\n",
       "  814,\n",
       "  815,\n",
       "  820,\n",
       "  825,\n",
       "  827,\n",
       "  829,\n",
       "  830,\n",
       "  832,\n",
       "  833,\n",
       "  837,\n",
       "  839,\n",
       "  843,\n",
       "  852,\n",
       "  855,\n",
       "  856,\n",
       "  858,\n",
       "  859,\n",
       "  862,\n",
       "  865,\n",
       "  866,\n",
       "  870,\n",
       "  873,\n",
       "  874,\n",
       "  878,\n",
       "  882,\n",
       "  889,\n",
       "  892,\n",
       "  898,\n",
       "  900,\n",
       "  901,\n",
       "  903,\n",
       "  905,\n",
       "  909,\n",
       "  914,\n",
       "  918,\n",
       "  920,\n",
       "  921,\n",
       "  927,\n",
       "  938,\n",
       "  943,\n",
       "  944,\n",
       "  946,\n",
       "  948,\n",
       "  955,\n",
       "  958,\n",
       "  959,\n",
       "  960,\n",
       "  967,\n",
       "  968,\n",
       "  982,\n",
       "  984,\n",
       "  986,\n",
       "  995,\n",
       "  997,\n",
       "  1000,\n",
       "  1002,\n",
       "  1004,\n",
       "  1005,\n",
       "  1007,\n",
       "  1018,\n",
       "  1019,\n",
       "  1021,\n",
       "  1032,\n",
       "  1035,\n",
       "  1040,\n",
       "  1050,\n",
       "  1052,\n",
       "  1056,\n",
       "  1061,\n",
       "  1062,\n",
       "  1066,\n",
       "  1073,\n",
       "  1074,\n",
       "  1076,\n",
       "  1079,\n",
       "  1080,\n",
       "  1083,\n",
       "  1085,\n",
       "  1087,\n",
       "  1093,\n",
       "  1099,\n",
       "  1100,\n",
       "  1104,\n",
       "  1105,\n",
       "  1108,\n",
       "  1110,\n",
       "  1113,\n",
       "  1115,\n",
       "  1120,\n",
       "  1126,\n",
       "  1133,\n",
       "  1138,\n",
       "  1139,\n",
       "  1143,\n",
       "  1145,\n",
       "  1147,\n",
       "  1150],\n",
       " (0, 0): [1152,\n",
       "  1153,\n",
       "  1154,\n",
       "  1155,\n",
       "  1156,\n",
       "  1157,\n",
       "  1159,\n",
       "  1160,\n",
       "  1162,\n",
       "  1163,\n",
       "  1165,\n",
       "  1166,\n",
       "  1167,\n",
       "  1168,\n",
       "  1171,\n",
       "  1172,\n",
       "  1173,\n",
       "  1174,\n",
       "  1175,\n",
       "  1176,\n",
       "  1178,\n",
       "  1179,\n",
       "  1180,\n",
       "  1181,\n",
       "  1185,\n",
       "  1187,\n",
       "  1188,\n",
       "  1189,\n",
       "  1191,\n",
       "  1193,\n",
       "  1194,\n",
       "  1196,\n",
       "  1197,\n",
       "  1201,\n",
       "  1202,\n",
       "  1203,\n",
       "  1204,\n",
       "  1206,\n",
       "  1207,\n",
       "  1209,\n",
       "  1210,\n",
       "  1211,\n",
       "  1212,\n",
       "  1213,\n",
       "  1214,\n",
       "  1216,\n",
       "  1217,\n",
       "  1218,\n",
       "  1219,\n",
       "  1220,\n",
       "  1221,\n",
       "  1222,\n",
       "  1223,\n",
       "  1224,\n",
       "  1225,\n",
       "  1226,\n",
       "  1227,\n",
       "  1228,\n",
       "  1229,\n",
       "  1230,\n",
       "  1232,\n",
       "  1233,\n",
       "  1234,\n",
       "  1235,\n",
       "  1236,\n",
       "  1238,\n",
       "  1239,\n",
       "  1241,\n",
       "  1242,\n",
       "  1244,\n",
       "  1246,\n",
       "  1247,\n",
       "  1248,\n",
       "  1250,\n",
       "  1251,\n",
       "  1252,\n",
       "  1253,\n",
       "  1254,\n",
       "  1255,\n",
       "  1256,\n",
       "  1257,\n",
       "  1259,\n",
       "  1260,\n",
       "  1261,\n",
       "  1263,\n",
       "  1264,\n",
       "  1265,\n",
       "  1266,\n",
       "  1271,\n",
       "  1273,\n",
       "  1274,\n",
       "  1275,\n",
       "  1276,\n",
       "  1277,\n",
       "  1278,\n",
       "  1279,\n",
       "  1280,\n",
       "  1282,\n",
       "  1283,\n",
       "  1288,\n",
       "  1289,\n",
       "  1290,\n",
       "  1291,\n",
       "  1292,\n",
       "  1293,\n",
       "  1294,\n",
       "  1295,\n",
       "  1296,\n",
       "  1297,\n",
       "  1298,\n",
       "  1299,\n",
       "  1300,\n",
       "  1301,\n",
       "  1302,\n",
       "  1303,\n",
       "  1304,\n",
       "  1305,\n",
       "  1306,\n",
       "  1307,\n",
       "  1309,\n",
       "  1310,\n",
       "  1311,\n",
       "  1312,\n",
       "  1313,\n",
       "  1314,\n",
       "  1315,\n",
       "  1317,\n",
       "  1318,\n",
       "  1319,\n",
       "  1320,\n",
       "  1321,\n",
       "  1322,\n",
       "  1323,\n",
       "  1325,\n",
       "  1326,\n",
       "  1327,\n",
       "  1328,\n",
       "  1330,\n",
       "  1331,\n",
       "  1332,\n",
       "  1333,\n",
       "  1335,\n",
       "  1336,\n",
       "  1337,\n",
       "  1338,\n",
       "  1340,\n",
       "  1341,\n",
       "  1342,\n",
       "  1343,\n",
       "  1344,\n",
       "  1345,\n",
       "  1346,\n",
       "  1347,\n",
       "  1348,\n",
       "  1349,\n",
       "  1350,\n",
       "  1351,\n",
       "  1352,\n",
       "  1353,\n",
       "  1355,\n",
       "  1357,\n",
       "  1359,\n",
       "  1360,\n",
       "  1361,\n",
       "  1362,\n",
       "  1363,\n",
       "  1364,\n",
       "  1365,\n",
       "  1366,\n",
       "  1368,\n",
       "  1369,\n",
       "  1370,\n",
       "  1371,\n",
       "  1372,\n",
       "  1373,\n",
       "  1374,\n",
       "  1375,\n",
       "  1376,\n",
       "  1377,\n",
       "  1378,\n",
       "  1379,\n",
       "  1380,\n",
       "  1381,\n",
       "  1382,\n",
       "  1383,\n",
       "  1384,\n",
       "  1385,\n",
       "  1386,\n",
       "  1389,\n",
       "  1390,\n",
       "  1391,\n",
       "  1392,\n",
       "  1393,\n",
       "  1394,\n",
       "  1395,\n",
       "  1396,\n",
       "  1397,\n",
       "  1398,\n",
       "  1399,\n",
       "  1401,\n",
       "  1402,\n",
       "  1403,\n",
       "  1404,\n",
       "  1405,\n",
       "  1406,\n",
       "  1407,\n",
       "  1408,\n",
       "  1410,\n",
       "  1411,\n",
       "  1412,\n",
       "  1413,\n",
       "  1414,\n",
       "  1415,\n",
       "  1416,\n",
       "  1417,\n",
       "  1418,\n",
       "  1419,\n",
       "  1422,\n",
       "  1423,\n",
       "  1425,\n",
       "  1426,\n",
       "  1427,\n",
       "  1428,\n",
       "  1429,\n",
       "  1430,\n",
       "  1431,\n",
       "  1432,\n",
       "  1433,\n",
       "  1434,\n",
       "  1436,\n",
       "  1438,\n",
       "  1439,\n",
       "  1440,\n",
       "  1443,\n",
       "  1444,\n",
       "  1445,\n",
       "  1446,\n",
       "  1447,\n",
       "  1448,\n",
       "  1450,\n",
       "  1451,\n",
       "  1452,\n",
       "  1454,\n",
       "  1455,\n",
       "  1456,\n",
       "  1458,\n",
       "  1459,\n",
       "  1460,\n",
       "  1462,\n",
       "  1463,\n",
       "  1464,\n",
       "  1465,\n",
       "  1466,\n",
       "  1469,\n",
       "  1470,\n",
       "  1471,\n",
       "  1473,\n",
       "  1474,\n",
       "  1476,\n",
       "  1477,\n",
       "  1478,\n",
       "  1479,\n",
       "  1480,\n",
       "  1482,\n",
       "  1483,\n",
       "  1484,\n",
       "  1485,\n",
       "  1486,\n",
       "  1487,\n",
       "  1489,\n",
       "  1490,\n",
       "  1491,\n",
       "  1492,\n",
       "  1493,\n",
       "  1494,\n",
       "  1495,\n",
       "  1496,\n",
       "  1497,\n",
       "  1498,\n",
       "  1499,\n",
       "  1500,\n",
       "  1505,\n",
       "  1506,\n",
       "  1507,\n",
       "  1508,\n",
       "  1510,\n",
       "  1511,\n",
       "  1512,\n",
       "  1513,\n",
       "  1514,\n",
       "  1515,\n",
       "  1518,\n",
       "  1519,\n",
       "  1521,\n",
       "  1522,\n",
       "  1523,\n",
       "  1524,\n",
       "  1525,\n",
       "  1526,\n",
       "  1527,\n",
       "  1528,\n",
       "  1529,\n",
       "  1530,\n",
       "  1532,\n",
       "  1533,\n",
       "  1534,\n",
       "  1535,\n",
       "  1536,\n",
       "  1537,\n",
       "  1538,\n",
       "  1539,\n",
       "  1540,\n",
       "  1541,\n",
       "  1542,\n",
       "  1543,\n",
       "  1544,\n",
       "  1545,\n",
       "  1546,\n",
       "  1547,\n",
       "  1548,\n",
       "  1549,\n",
       "  1550,\n",
       "  1551,\n",
       "  1552,\n",
       "  1553,\n",
       "  1554,\n",
       "  1555,\n",
       "  1556,\n",
       "  1557,\n",
       "  1558,\n",
       "  1559,\n",
       "  1561,\n",
       "  1562,\n",
       "  1563,\n",
       "  1564,\n",
       "  1566,\n",
       "  1567,\n",
       "  1568,\n",
       "  1569,\n",
       "  1570,\n",
       "  1571,\n",
       "  1574,\n",
       "  1575,\n",
       "  1576,\n",
       "  1577,\n",
       "  1578,\n",
       "  1579,\n",
       "  1580,\n",
       "  1581,\n",
       "  1582,\n",
       "  1583,\n",
       "  1585,\n",
       "  1586,\n",
       "  1589,\n",
       "  1590,\n",
       "  1591,\n",
       "  1592,\n",
       "  1593,\n",
       "  1594,\n",
       "  1595,\n",
       "  1596,\n",
       "  1597,\n",
       "  1598,\n",
       "  1599,\n",
       "  1600,\n",
       "  1601,\n",
       "  1602,\n",
       "  1603,\n",
       "  1604,\n",
       "  1605,\n",
       "  1606,\n",
       "  1609,\n",
       "  1610,\n",
       "  1612,\n",
       "  1613,\n",
       "  1615,\n",
       "  1616,\n",
       "  1617,\n",
       "  1618,\n",
       "  1620,\n",
       "  1621,\n",
       "  1622,\n",
       "  1623,\n",
       "  1624,\n",
       "  1625,\n",
       "  1626,\n",
       "  1627,\n",
       "  1628,\n",
       "  1630,\n",
       "  1631,\n",
       "  1633,\n",
       "  1634,\n",
       "  1635,\n",
       "  1636,\n",
       "  1637,\n",
       "  1638,\n",
       "  1639,\n",
       "  1640,\n",
       "  1641,\n",
       "  1642,\n",
       "  1644,\n",
       "  1645,\n",
       "  1646,\n",
       "  1647,\n",
       "  1648,\n",
       "  1649,\n",
       "  1650,\n",
       "  1651,\n",
       "  1652,\n",
       "  1653,\n",
       "  1655,\n",
       "  1656,\n",
       "  1657,\n",
       "  1658,\n",
       "  1659,\n",
       "  1660,\n",
       "  1661,\n",
       "  1662,\n",
       "  1664,\n",
       "  1665,\n",
       "  1666,\n",
       "  1667,\n",
       "  1668,\n",
       "  1669,\n",
       "  1670,\n",
       "  1671,\n",
       "  1672,\n",
       "  1673,\n",
       "  1675,\n",
       "  1676,\n",
       "  1677,\n",
       "  1678,\n",
       "  1679,\n",
       "  1680,\n",
       "  1682,\n",
       "  1683,\n",
       "  1684,\n",
       "  1685,\n",
       "  1687,\n",
       "  1688,\n",
       "  1689,\n",
       "  1691,\n",
       "  1692,\n",
       "  1693,\n",
       "  1694,\n",
       "  1696,\n",
       "  1698,\n",
       "  1700,\n",
       "  1701,\n",
       "  1703,\n",
       "  1705,\n",
       "  1707,\n",
       "  1708,\n",
       "  1709,\n",
       "  1710,\n",
       "  1711,\n",
       "  1712,\n",
       "  1713,\n",
       "  1714,\n",
       "  1715,\n",
       "  1717,\n",
       "  1718,\n",
       "  1720,\n",
       "  1721,\n",
       "  1722,\n",
       "  1723,\n",
       "  1724,\n",
       "  1726,\n",
       "  1728,\n",
       "  1729,\n",
       "  1730,\n",
       "  1731,\n",
       "  1732,\n",
       "  1734,\n",
       "  1735,\n",
       "  1736,\n",
       "  1737,\n",
       "  1738,\n",
       "  1740,\n",
       "  1741,\n",
       "  1742,\n",
       "  1743,\n",
       "  1745,\n",
       "  1746,\n",
       "  1747,\n",
       "  1748,\n",
       "  1749,\n",
       "  1750,\n",
       "  1751,\n",
       "  1752,\n",
       "  1753,\n",
       "  1754,\n",
       "  1755,\n",
       "  1757,\n",
       "  1758,\n",
       "  1759,\n",
       "  1760,\n",
       "  1761,\n",
       "  1763,\n",
       "  1764,\n",
       "  1765,\n",
       "  1766,\n",
       "  1767,\n",
       "  1769,\n",
       "  1770,\n",
       "  1771,\n",
       "  1773,\n",
       "  1775,\n",
       "  1776,\n",
       "  1777,\n",
       "  1778,\n",
       "  1780,\n",
       "  1781,\n",
       "  1782,\n",
       "  1784,\n",
       "  1785,\n",
       "  1786,\n",
       "  1790,\n",
       "  1791,\n",
       "  1792,\n",
       "  1794,\n",
       "  1795,\n",
       "  1796,\n",
       "  1797,\n",
       "  1798,\n",
       "  1799,\n",
       "  1800,\n",
       "  1802,\n",
       "  1803,\n",
       "  1804,\n",
       "  1806,\n",
       "  1808,\n",
       "  1809,\n",
       "  1810,\n",
       "  1811,\n",
       "  1813,\n",
       "  1815,\n",
       "  1816,\n",
       "  1817,\n",
       "  1818,\n",
       "  1819,\n",
       "  1820,\n",
       "  1821,\n",
       "  1822,\n",
       "  1823,\n",
       "  1824,\n",
       "  1825,\n",
       "  1826,\n",
       "  1827,\n",
       "  1828,\n",
       "  1829,\n",
       "  1831,\n",
       "  1832,\n",
       "  1833,\n",
       "  1834,\n",
       "  1836,\n",
       "  1837,\n",
       "  1838,\n",
       "  1839,\n",
       "  1841,\n",
       "  1842,\n",
       "  1843,\n",
       "  1844,\n",
       "  1845,\n",
       "  1846,\n",
       "  1847,\n",
       "  1848,\n",
       "  1849,\n",
       "  1851,\n",
       "  1852,\n",
       "  1853,\n",
       "  1857,\n",
       "  1858,\n",
       "  1859,\n",
       "  1860,\n",
       "  1861,\n",
       "  1862,\n",
       "  1864,\n",
       "  1866,\n",
       "  1867,\n",
       "  1868,\n",
       "  1869,\n",
       "  1870,\n",
       "  1871,\n",
       "  1872,\n",
       "  1873,\n",
       "  1875,\n",
       "  1876,\n",
       "  1879,\n",
       "  1881,\n",
       "  1882,\n",
       "  1883,\n",
       "  1884,\n",
       "  1885,\n",
       "  1886,\n",
       "  1887,\n",
       "  1888,\n",
       "  1889,\n",
       "  1890,\n",
       "  1891,\n",
       "  1892,\n",
       "  1893,\n",
       "  1894,\n",
       "  1895,\n",
       "  1896,\n",
       "  1897,\n",
       "  1898,\n",
       "  1899,\n",
       "  1900,\n",
       "  1901,\n",
       "  1902,\n",
       "  1903,\n",
       "  1905,\n",
       "  1906,\n",
       "  1907,\n",
       "  1908,\n",
       "  1909,\n",
       "  1910,\n",
       "  1911,\n",
       "  1912,\n",
       "  1913,\n",
       "  1914,\n",
       "  1915,\n",
       "  1916,\n",
       "  1917,\n",
       "  1918,\n",
       "  1919,\n",
       "  1920,\n",
       "  1921,\n",
       "  1922,\n",
       "  1923,\n",
       "  1924,\n",
       "  1925,\n",
       "  1926,\n",
       "  1927,\n",
       "  1928,\n",
       "  1930,\n",
       "  1931,\n",
       "  1932,\n",
       "  1933,\n",
       "  1934,\n",
       "  1936,\n",
       "  1937,\n",
       "  1938,\n",
       "  1939,\n",
       "  1940,\n",
       "  1941,\n",
       "  1942,\n",
       "  1943,\n",
       "  1944,\n",
       "  1945,\n",
       "  1948,\n",
       "  1949,\n",
       "  1950,\n",
       "  1951,\n",
       "  1952,\n",
       "  1953,\n",
       "  1954,\n",
       "  1955,\n",
       "  1956,\n",
       "  1957,\n",
       "  1958,\n",
       "  1959,\n",
       "  1961,\n",
       "  1962,\n",
       "  1964,\n",
       "  1965,\n",
       "  1966,\n",
       "  1967,\n",
       "  1968,\n",
       "  1969,\n",
       "  1970,\n",
       "  1973,\n",
       "  1974,\n",
       "  1975,\n",
       "  1976,\n",
       "  1977,\n",
       "  1978,\n",
       "  1979,\n",
       "  1980,\n",
       "  1981,\n",
       "  1982,\n",
       "  1983,\n",
       "  1984,\n",
       "  1985,\n",
       "  1986,\n",
       "  1988,\n",
       "  1989,\n",
       "  1990,\n",
       "  1991,\n",
       "  1992,\n",
       "  1993,\n",
       "  1994,\n",
       "  1995,\n",
       "  1996,\n",
       "  1998,\n",
       "  1999,\n",
       "  2002,\n",
       "  2003,\n",
       "  2004,\n",
       "  2005,\n",
       "  2006,\n",
       "  2007,\n",
       "  2008,\n",
       "  2009,\n",
       "  2010,\n",
       "  2011,\n",
       "  2012,\n",
       "  2013,\n",
       "  2015,\n",
       "  2016,\n",
       "  2017,\n",
       "  2018,\n",
       "  2019,\n",
       "  2021,\n",
       "  2022,\n",
       "  2023,\n",
       "  2024,\n",
       "  2025,\n",
       "  2026,\n",
       "  2027,\n",
       "  2029,\n",
       "  2030,\n",
       "  2032,\n",
       "  2033,\n",
       "  2034,\n",
       "  2035,\n",
       "  2036,\n",
       "  2038,\n",
       "  2040,\n",
       "  2041,\n",
       "  2042,\n",
       "  2043,\n",
       "  2044,\n",
       "  2045,\n",
       "  2046,\n",
       "  2047,\n",
       "  2048,\n",
       "  2049,\n",
       "  2050,\n",
       "  2051,\n",
       "  2053,\n",
       "  2054,\n",
       "  2055,\n",
       "  2057,\n",
       "  2058,\n",
       "  2059,\n",
       "  2061,\n",
       "  2062,\n",
       "  2063,\n",
       "  2064,\n",
       "  2065,\n",
       "  2066,\n",
       "  2068,\n",
       "  2069,\n",
       "  2070,\n",
       "  2071,\n",
       "  2072,\n",
       "  2073,\n",
       "  2074,\n",
       "  2075,\n",
       "  2076,\n",
       "  2077,\n",
       "  2078,\n",
       "  2080,\n",
       "  2081,\n",
       "  2082,\n",
       "  2083,\n",
       "  2084,\n",
       "  2085,\n",
       "  2086,\n",
       "  2087,\n",
       "  2088,\n",
       "  2089,\n",
       "  2091,\n",
       "  2092,\n",
       "  2093,\n",
       "  2094,\n",
       "  2095,\n",
       "  2096,\n",
       "  2097,\n",
       "  2098,\n",
       "  2099,\n",
       "  2100,\n",
       "  2101,\n",
       "  2102,\n",
       "  2103,\n",
       "  2104,\n",
       "  2105,\n",
       "  2106,\n",
       "  2107,\n",
       "  2108,\n",
       "  2109,\n",
       "  2110,\n",
       "  2112,\n",
       "  2113,\n",
       "  2114,\n",
       "  2115,\n",
       "  2117,\n",
       "  2119,\n",
       "  2120,\n",
       "  2121,\n",
       "  2123,\n",
       "  2124,\n",
       "  2125,\n",
       "  2126,\n",
       "  2127,\n",
       "  2128,\n",
       "  2129,\n",
       "  2130,\n",
       "  2132,\n",
       "  2134,\n",
       "  2135,\n",
       "  2136,\n",
       "  2137,\n",
       "  2138,\n",
       "  2139,\n",
       "  2140,\n",
       "  2142,\n",
       "  2144,\n",
       "  2145,\n",
       "  2146,\n",
       "  2148,\n",
       "  2149,\n",
       "  2151,\n",
       "  2152,\n",
       "  2153,\n",
       "  2154,\n",
       "  2155,\n",
       "  2156,\n",
       "  2157,\n",
       "  2158,\n",
       "  2159,\n",
       "  2160,\n",
       "  2161,\n",
       "  2162,\n",
       "  2163,\n",
       "  2164,\n",
       "  2165,\n",
       "  2166,\n",
       "  2167,\n",
       "  2168,\n",
       "  2170,\n",
       "  2171,\n",
       "  2172,\n",
       "  2173,\n",
       "  2174,\n",
       "  2175,\n",
       "  2177,\n",
       "  2178,\n",
       "  2179,\n",
       "  2181,\n",
       "  2183,\n",
       "  2184,\n",
       "  2185,\n",
       "  2186,\n",
       "  2187,\n",
       "  2188,\n",
       "  2190,\n",
       "  2191,\n",
       "  2192,\n",
       "  2193,\n",
       "  2194,\n",
       "  2195,\n",
       "  2197,\n",
       "  2198,\n",
       "  2199,\n",
       "  2200,\n",
       "  2201,\n",
       "  2202,\n",
       "  2203,\n",
       "  2204,\n",
       "  2205,\n",
       "  2206,\n",
       "  2207,\n",
       "  2208,\n",
       "  2210,\n",
       "  2211,\n",
       "  2212,\n",
       "  2213,\n",
       "  2214,\n",
       "  2215,\n",
       "  2216,\n",
       "  2218,\n",
       "  2219,\n",
       "  2220,\n",
       "  2222,\n",
       "  2224,\n",
       "  2225,\n",
       "  2226,\n",
       "  2227,\n",
       "  2228,\n",
       "  2229,\n",
       "  2230,\n",
       "  2231,\n",
       "  2232,\n",
       "  2235,\n",
       "  2236,\n",
       "  2239,\n",
       "  2240,\n",
       "  2241,\n",
       "  2242,\n",
       "  2245,\n",
       "  2246,\n",
       "  2247,\n",
       "  2248,\n",
       "  2249,\n",
       "  2250,\n",
       "  2251,\n",
       "  2253,\n",
       "  2254,\n",
       "  2255,\n",
       "  2256,\n",
       "  2257,\n",
       "  2258,\n",
       "  2259,\n",
       "  2260,\n",
       "  2261,\n",
       "  2262,\n",
       "  2263,\n",
       "  2264,\n",
       "  2265,\n",
       "  2266,\n",
       "  2267,\n",
       "  2268,\n",
       "  2270,\n",
       "  2271,\n",
       "  2272,\n",
       "  2273,\n",
       "  2274,\n",
       "  2275,\n",
       "  2276,\n",
       "  2277,\n",
       "  2278,\n",
       "  2279,\n",
       "  2281,\n",
       "  2282,\n",
       "  2283,\n",
       "  2284,\n",
       "  2285,\n",
       "  2286,\n",
       "  2288,\n",
       "  2289,\n",
       "  2290,\n",
       "  2291,\n",
       "  2292,\n",
       "  2293,\n",
       "  2294,\n",
       "  2295,\n",
       "  2296,\n",
       "  2297,\n",
       "  2298,\n",
       "  2299,\n",
       "  2300,\n",
       "  2301],\n",
       " (1, 0): [1158,\n",
       "  1161,\n",
       "  1164,\n",
       "  1169,\n",
       "  1170,\n",
       "  1177,\n",
       "  1182,\n",
       "  1183,\n",
       "  1184,\n",
       "  1186,\n",
       "  1190,\n",
       "  1192,\n",
       "  1195,\n",
       "  1198,\n",
       "  1199,\n",
       "  1200,\n",
       "  1205,\n",
       "  1208,\n",
       "  1215,\n",
       "  1231,\n",
       "  1237,\n",
       "  1240,\n",
       "  1243,\n",
       "  1245,\n",
       "  1249,\n",
       "  1258,\n",
       "  1262,\n",
       "  1267,\n",
       "  1268,\n",
       "  1269,\n",
       "  1270,\n",
       "  1272,\n",
       "  1281,\n",
       "  1284,\n",
       "  1285,\n",
       "  1286,\n",
       "  1287,\n",
       "  1308,\n",
       "  1316,\n",
       "  1324,\n",
       "  1329,\n",
       "  1334,\n",
       "  1339,\n",
       "  1354,\n",
       "  1356,\n",
       "  1358,\n",
       "  1367,\n",
       "  1387,\n",
       "  1388,\n",
       "  1400,\n",
       "  1409,\n",
       "  1420,\n",
       "  1421,\n",
       "  1424,\n",
       "  1435,\n",
       "  1437,\n",
       "  1441,\n",
       "  1442,\n",
       "  1449,\n",
       "  1453,\n",
       "  1457,\n",
       "  1461,\n",
       "  1467,\n",
       "  1468,\n",
       "  1472,\n",
       "  1475,\n",
       "  1481,\n",
       "  1488,\n",
       "  1501,\n",
       "  1502,\n",
       "  1503,\n",
       "  1504,\n",
       "  1509,\n",
       "  1516,\n",
       "  1517,\n",
       "  1520,\n",
       "  1531,\n",
       "  1560,\n",
       "  1565,\n",
       "  1572,\n",
       "  1573,\n",
       "  1584,\n",
       "  1587,\n",
       "  1588,\n",
       "  1607,\n",
       "  1608,\n",
       "  1611,\n",
       "  1614,\n",
       "  1619,\n",
       "  1629,\n",
       "  1632,\n",
       "  1643,\n",
       "  1654,\n",
       "  1663,\n",
       "  1674,\n",
       "  1681,\n",
       "  1686,\n",
       "  1690,\n",
       "  1695,\n",
       "  1697,\n",
       "  1699,\n",
       "  1702,\n",
       "  1704,\n",
       "  1706,\n",
       "  1716,\n",
       "  1719,\n",
       "  1725,\n",
       "  1727,\n",
       "  1733,\n",
       "  1739,\n",
       "  1744,\n",
       "  1756,\n",
       "  1762,\n",
       "  1768,\n",
       "  1772,\n",
       "  1774,\n",
       "  1779,\n",
       "  1783,\n",
       "  1787,\n",
       "  1788,\n",
       "  1789,\n",
       "  1793,\n",
       "  1801,\n",
       "  1805,\n",
       "  1807,\n",
       "  1812,\n",
       "  1814,\n",
       "  1830,\n",
       "  1835,\n",
       "  1840,\n",
       "  1850,\n",
       "  1854,\n",
       "  1855,\n",
       "  1856,\n",
       "  1863,\n",
       "  1865,\n",
       "  1874,\n",
       "  1877,\n",
       "  1878,\n",
       "  1880,\n",
       "  1904,\n",
       "  1929,\n",
       "  1935,\n",
       "  1946,\n",
       "  1947,\n",
       "  1960,\n",
       "  1963,\n",
       "  1971,\n",
       "  1972,\n",
       "  1987,\n",
       "  1997,\n",
       "  2000,\n",
       "  2001,\n",
       "  2014,\n",
       "  2020,\n",
       "  2028,\n",
       "  2031,\n",
       "  2037,\n",
       "  2039,\n",
       "  2052,\n",
       "  2056,\n",
       "  2060,\n",
       "  2067,\n",
       "  2079,\n",
       "  2090,\n",
       "  2111,\n",
       "  2116,\n",
       "  2118,\n",
       "  2122,\n",
       "  2131,\n",
       "  2133,\n",
       "  2141,\n",
       "  2143,\n",
       "  2147,\n",
       "  2150,\n",
       "  2169,\n",
       "  2176,\n",
       "  2180,\n",
       "  2182,\n",
       "  2189,\n",
       "  2196,\n",
       "  2209,\n",
       "  2217,\n",
       "  2221,\n",
       "  2223,\n",
       "  2233,\n",
       "  2234,\n",
       "  2237,\n",
       "  2238,\n",
       "  2243,\n",
       "  2244,\n",
       "  2252,\n",
       "  2269,\n",
       "  2280,\n",
       "  2287]}"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 1) 836\n",
      "(1, 1) 316\n",
      "(0, 0) 955\n",
      "(1, 0) 195\n"
     ]
    }
   ],
   "source": [
    "for i in prediction_case:\n",
    "    print(i, len(prediction_case[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mixed wiki, cresci model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Twice as much wiki as Cresci, lower overall training data volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "wc_human = cleaned_wiki + cresci_gen_train[:len(cleaned_wiki)//2]\n",
    "\n",
    "np.random.shuffle(wc_human)\n",
    "\n",
    "wc_human_train = wc_human[:-1000]\n",
    "wc_human_val = wc_human[-1000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "wc_bot = cleaned_gen + cresci_spam_train[:len(cleaned_gen)//2]\n",
    "\n",
    "np.random.shuffle(wc_bot)\n",
    "\n",
    "wc_bot_train = wc_bot[:-1000]\n",
    "wc_bot_val = wc_bot[-1000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14850"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(wc_human)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### One to one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "wc_human = cleaned_wiki + cresci_gen_train[:len(cleaned_wiki)]\n",
    "\n",
    "np.random.shuffle(wc_human)\n",
    "\n",
    "wc_human_train = wc_human[:-1000]\n",
    "wc_human_val = wc_human[-1000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "wc_bot = cleaned_gen + cresci_spam_train[:len(cleaned_gen)]\n",
    "\n",
    "np.random.shuffle(wc_bot)\n",
    "\n",
    "wc_bot_train = wc_bot[:-1000]\n",
    "wc_bot_val = wc_bot[-1000:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Twice as much Cresci as wiki, overall higher number of training examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "wc_human = cleaned_wiki + cresci_gen_train[:len(cleaned_wiki)*2]\n",
    "\n",
    "np.random.shuffle(wc_human)\n",
    "\n",
    "wc_human_train = wc_human[:-1000]\n",
    "wc_human_val = wc_human[-1000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "wc_bot = cleaned_gen + cresci_spam_train[:len(cleaned_gen)*2]\n",
    "\n",
    "np.random.shuffle(wc_bot)\n",
    "\n",
    "wc_bot_train = wc_bot[:-1000]\n",
    "wc_bot_val = wc_bot[-1000:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Label and Tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "wc_train = wc_human_train + wc_bot_train\n",
    "wc_train_labels = np.array([0]*len(wc_human_train) + [1]*len(wc_bot_train))\n",
    "\n",
    "wc_val = wc_human_val + wc_bot_val\n",
    "wc_val_labels = np.array([0]*len(wc_human_val) + [1]*len(wc_bot_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "wc_train_encodings = tokenizer(wc_train, truncation=True, padding=True, max_length=100, return_tensors='tf')\n",
    "wc_val_encodings = tokenizer(wc_val, truncation=True, padding=True, max_length=100, return_tensors='tf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at roberta-base were not used when initializing TFRobertaModel: ['lm_head']\n",
      "- This IS expected if you are initializing TFRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFRobertaModel were initialized from the model checkpoint at roberta-base.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "7175/7175 [==============================] - 728s 101ms/step - loss: 0.0905 - accuracy: 0.9671 - precision_3: 0.9753 - recall_3: 0.9585 - val_loss: 0.0795 - val_accuracy: 0.9735 - val_precision_3: 0.9788 - val_recall_3: 0.9680\n",
      "Epoch 2/2\n",
      "7175/7175 [==============================] - 719s 100ms/step - loss: 0.0506 - accuracy: 0.9827 - precision_3: 0.9888 - recall_3: 0.9764 - val_loss: 0.0757 - val_accuracy: 0.9780 - val_precision_3: 0.9819 - val_recall_3: 0.9740\n"
     ]
    }
   ],
   "source": [
    "wc_model = build_base_roberta(learning_rate = 0.00001,\n",
    "                      dropout=0.35,\n",
    "                      hidden_size=150)\n",
    "wc_model_history = wc_model.fit([wc_train_encodings.input_ids, wc_train_encodings.attention_mask], \n",
    "                                                  wc_train_labels,   \n",
    "                                                  validation_data=([wc_val_encodings.input_ids, wc_val_encodings.attention_mask], \n",
    "                                                  wc_val_labels),    \n",
    "                                                  batch_size=8, \n",
    "                                                  epochs=2, shuffle=True,)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tweep Fake manually curated accounts training set for model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27700"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(wc_train_encodings.input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweep_train = pd.read_csv('/home/brody/school/w266/tweep_fake/train.csv')\n",
    "\n",
    "tweep_train['labels'] = tweep_train.apply(lambda x: 0 if x['account.type']=='human' else 1, axis=1)\n",
    "\n",
    "tweep_train_text = tweep_train['text'].to_numpy().tolist()\n",
    "tweep_train_labels = tweep_train['labels'].to_numpy()\n",
    "\n",
    "tweep_train_encodings = tokenizer(tweep_train_text, truncation=True, padding=True, max_length=100, return_tensors='tf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate for 2 wiki to 1 cresci"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162/162 [==============================] - 66s 397ms/step - loss: 1.1513 - accuracy: 0.6036 - precision_1: 0.7040 - recall_1: 0.3573\n"
     ]
    }
   ],
   "source": [
    "wiki2_cresci1 = wc_model.evaluate([tweep_train_encodings.input_ids, tweep_train_encodings.attention_mask], \n",
    "                                  tweep_train_labels, batch_size=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate for 1 to 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162/162 [==============================] - 68s 411ms/step - loss: 1.4593 - accuracy: 0.5237 - precision_2: 0.5885 - recall_2: 0.1570\n"
     ]
    }
   ],
   "source": [
    "wiki1_cresci1 = wc_model.evaluate([tweep_train_encodings.input_ids, tweep_train_encodings.attention_mask], \n",
    "                                  tweep_train_labels, batch_size=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate for 2 cresci to 1 wiki"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162/162 [==============================] - 68s 411ms/step - loss: 1.5910 - accuracy: 0.5377 - precision_3: 0.6301 - recall_3: 0.1822\n"
     ]
    }
   ],
   "source": [
    "wiki1_cresci2 = wc_model.evaluate([tweep_train_encodings.input_ids, tweep_train_encodings.attention_mask], \n",
    "                                  tweep_train_labels, batch_size=128)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "38_ve",
   "language": "python",
   "name": "38_ve"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
